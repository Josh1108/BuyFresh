{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ueRAiY2Y1ma"
      },
      "source": [
        "# 10-714 Homework 4\n",
        "\n",
        "In this homework, you will leverage all of the components built in the last three homeworks to solve some modern problems with high performing network structures. We will start by adding a few new ops leveraging our new CPU/CUDA backends. Then, you will implement convolution, and a convolutional neural network to train a classifier on the CIFAR-10 image classification dataset. Then, you will implement recurrent and long-short term memory (LSTM) neural networks, and do word-level prediction language modeling on the Penn Treebank dataset.\n",
        "\n",
        "As always, we will start by copying this notebook and getting the starting code.\n",
        "Reminder: __you must save a copy in drive__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xciYq2YkY1md",
        "outputId": "3c15c272-ce86-4205-b696-5c5df8ccfa42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive/10714\n",
            "fatal: destination path 'hw4' already exists and is not an empty directory.\n",
            "/content/drive/MyDrive/10714/hw4\n",
            "Collecting git+https://github.com/dlsys10714/mugrade.git\n",
            "  Cloning https://github.com/dlsys10714/mugrade.git to /tmp/pip-req-build-wzi2mzb7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/dlsys10714/mugrade.git /tmp/pip-req-build-wzi2mzb7\n",
            "  Resolved https://github.com/dlsys10714/mugrade.git to commit 656cdc2b7ad5a37e7a5347a7b0405df0acd72380\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mugrade\n",
            "  Building wheel for mugrade (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mugrade: filename=mugrade-1.2-py3-none-any.whl size=3935 sha256=142abfdd8166ec495ed82315297ade429d3030be751632429c816e1e6b828f4d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9yh5l0at/wheels/8b/ba/3a/621da1207eab160c01968c5e0bd1266f505b9e3f8010376d61\n",
            "Successfully built mugrade\n",
            "Installing collected packages: mugrade\n",
            "Successfully installed mugrade-1.2\n",
            "Collecting pybind11\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Downloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pybind11\n",
            "Successfully installed pybind11-2.13.6\n"
          ]
        }
      ],
      "source": [
        "# Code to set up the assignment\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/\n",
        "!mkdir -p 10714\n",
        "%cd /content/drive/MyDrive/10714\n",
        "!git clone https://github.com/dlsys10714/hw4.git\n",
        "%cd /content/drive/MyDrive/10714/hw4\n",
        "\n",
        "!pip3 install --upgrade --no-deps git+https://github.com/dlsys10714/mugrade.git\n",
        "!pip3 install pybind11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJM8iOmhY1me",
        "outputId": "3302cfc2-9fd1-4512-cd44-31a2a7d8e730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Found pybind11: /usr/local/lib/python3.10/dist-packages/pybind11/include (found version \"2.13.6\")\n",
            "-- Found cuda, building cuda backend\n",
            "Tue Nov 19 03:24:53 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "-- Autodetected CUDA architecture(s):  7.5\n",
            "-- Configuring done (2.7s)\n",
            "-- Generating done (4.5s)\n",
            "-- Build files have been written to: /content/drive/MyDrive/10714/hw4/build\n",
            "make[1]: Entering directory '/content/drive/MyDrive/10714/hw4/build'\n",
            "make[2]: Entering directory '/content/drive/MyDrive/10714/hw4/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/hw4/build'\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/hw4/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/hw4/build'\n",
            "[-25%] \u001b[32mBuilding CXX object CMakeFiles/ndarray_backend_cpu.dir/src/ndarray_backend_cpu.cc.o\u001b[0m\n",
            "[  0%] \u001b[32m\u001b[1mLinking CXX shared module /content/drive/MyDrive/10714/hw4/python/needle/backend_ndarray/ndarray_backend_cpu.cpython-310-x86_64-linux-gnu.so\u001b[0m\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/hw4/build'\n",
            "[  0%] Built target ndarray_backend_cpu\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/hw4/build'\n",
            "[ 25%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/ndarray_backend_cuda.dir/src/ndarray_backend_cuda_generated_ndarray_backend_cuda.cu.o\u001b[0m\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/hw4/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/hw4/build'\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX shared module /content/drive/MyDrive/10714/hw4/python/needle/backend_ndarray/ndarray_backend_cuda.cpython-310-x86_64-linux-gnu.so\u001b[0m\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/hw4/build'\n",
            "[ 50%] Built target ndarray_backend_cuda\n",
            "make[2]: Leaving directory '/content/drive/MyDrive/10714/hw4/build'\n",
            "make[1]: Leaving directory '/content/drive/MyDrive/10714/hw4/build'\n"
          ]
        }
      ],
      "source": [
        "!make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDMLaX5yY1me",
        "outputId": "dd5701f3-5f81-4553-d9c1-586fed5971b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=./python\n",
            "env: NEEDLE_BACKEND=nd\n"
          ]
        }
      ],
      "source": [
        "%set_env PYTHONPATH ./python\n",
        "%set_env NEEDLE_BACKEND nd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eb6loZnbY1mf"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('./python')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JZwVmsatY1mf"
      },
      "outputs": [],
      "source": [
        "# Download the datasets you will be using for this assignment\n",
        "\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "!mkdir -p './data/ptb'\n",
        "# Download Penn Treebank dataset\n",
        "ptb_data = \"https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.\"\n",
        "for f in ['train.txt', 'test.txt', 'valid.txt']:\n",
        "    if not os.path.exists(os.path.join('./data/ptb', f)):\n",
        "        urllib.request.urlretrieve(ptb_data + f, os.path.join('./data/ptb', f))\n",
        "\n",
        "# Download CIFAR-10 dataset\n",
        "if not os.path.isdir(\"./data/cifar-10-batches-py\"):\n",
        "    urllib.request.urlretrieve(\"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\", \"./data/cifar-10-python.tar.gz\")\n",
        "    !tar -xvzf './data/cifar-10-python.tar.gz' -C './data'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRUxd_KVY1mf"
      },
      "source": [
        "To finish setting up the assignment, go ahead and fill in all the code in `python/needle/autograd.py` using your solution code from the previous homework. Also copy the solutions in `src/ndarray_backend_cpu.cc` and `src/ndarray_backend_cuda.cu` from homework 3.\n",
        "\n",
        "**Note**: Be careful not to accidentally delete or modify any new imports and function declarations when copying over code from previous assignments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq7at5DnY1mg"
      },
      "source": [
        "## Part 1: ND Backend [10 pts]\n",
        "\n",
        "Recall that in homework 2, the `array_api` was imported as `numpy`. In this part, the goal is to write the necessary operations with `array_api` imported from the needle backend `NDArray` in `python/needle/backend_ndarray/ndarray.py`. Make sure to copy the solutions for `reshape`, `permute`, `broadcast_to` and `__getitem__` from homework 3.\n",
        "\n",
        "Fill in the following classes in `python/needle/ops_logarithmic.py` and `python/needle/ops_mathematic.py`:\n",
        "\n",
        "- `PowerScalar`\n",
        "- `EWiseDiv`\n",
        "- `DivScalar`\n",
        "- `Transpose`\n",
        "- `Reshape`\n",
        "- `BroadcastTo`\n",
        "- `Summation`\n",
        "- `MatMul`\n",
        "- `Negate`\n",
        "- `Log`\n",
        "- `Exp`\n",
        "- `ReLU`\n",
        "- `LogSumExp`\n",
        "- `Tanh` (new)\n",
        "- `Stack` (new)\n",
        "- `Split` (new)\n",
        "\n",
        "Note that for most of these, you already wrote the solutions in the previous homework and you should not change most part of your previous solution, if issues arise, please check if the `array_api` function used is supported in the needle backend.\n",
        "\n",
        "The `Tanh`, `Stack`, and `Split` operators are newly added. `Stack` concatenates same-sized tensors along a new axis, and `Split` undoes this operation. The gradients of the two operations can be written in terms of each other. We do not directly test `Split`, and only test the backward pass of `Stack` (for which we assume you used `Split`).\n",
        "\n",
        "**Note:** You may want to make your Summation op support sums over multiple axes; you will likely need it for the backward pass of the BroadcastTo op if yours supports broadcasting over multiple axes at a time. However, this is more about ease of use than necessity, and we leave this decision up to you (there are no corresponding tests).\n",
        "\n",
        "**Note:** Depending on your implementations, you may want to ensure that you call `.compact()` before reshaping arrays. (If this is necessary, you will run into corresponding error messages later in the assignment.)\n",
        "\n",
        "**Note**: Be careful not to accidentally delete or modify any new imports and function declarations when copying over code from previous assignments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnSeTM9rY1mg"
      },
      "outputs": [],
      "source": [
        "!python3 -m pytest -l -v -k \"nd_backend\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJN_aDa6Y1mg"
      },
      "outputs": [],
      "source": [
        "!python3 -m mugrade submit \"YOUR KEY HERE\" -k \"new_nd_backend\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PONQMd-hY1mg"
      },
      "source": [
        "## Part 2: CIFAR-10 dataset [10 points]\n",
        "\n",
        "Next, you will write support for the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) image classification dataset, which consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. There are 50k training images and 10k test images.\n",
        "\n",
        "Start by implementing the `__init__` function in the `CIFAR10Dataset` class in `python/needle/data/datasets/cifar10_dataset.py`. You can read in the link above how to properly read the CIFAR-10 dataset files you downloaded at the beginning of the homework. Also fill in `__getitem__` and `__len__`. Note that the return shape of the data from `__getitem__` should be in order (3, 32, 32).\n",
        "\n",
        "Copy `python/needle/data/data_transforms.py` and `python/needle/data/data_basic.py` from previous homeworks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziQgOvD_Y1mh"
      },
      "outputs": [],
      "source": [
        "!python3 -m pytest -l -v -k \"test_cifar10\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8HR-ztfY1mh"
      },
      "outputs": [],
      "source": [
        "!python3 -m mugrade submit \"YOUR KEY HERE\" -k \"cifar10\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "PlsCg7JpY1mh"
      },
      "source": [
        "## Part 3: Convolutional neural network [40 points]\n",
        "\n",
        "Here's an outline of what you will do in this task.\n",
        "\n",
        "In `python/needle/backend_ndarray/ndarray.py`, implement:\n",
        "- `flip`\n",
        "- `pad`\n",
        "\n",
        "In `python/needle/ops_mathematic.py`, implement (forward and backward):\n",
        "- `Flip`\n",
        "- `Dilate`\n",
        "- `UnDilate`\n",
        "- `Conv`\n",
        "\n",
        "In `python/needle/nn/nn_conv.py`, implement:\n",
        "- `Conv`\n",
        "\n",
        "In `apps/models.py`, fill in the `ResNet9` class.  \n",
        "\n",
        "In `apps/simple_ml.py`, fill in:\n",
        "- `epoch_general_cifar10`,\n",
        "- `train_cifar10`\n",
        "- `evaluate_cifar10`\n",
        "\n",
        "We have provided a `BatchNorm2d` implementation in `python/needle/nn/nn_basic.py` for you as a wrapper around your previous `BatchNorm1d` implementation.\n",
        "\n",
        "**Note**: Remember to copy the solution of `nn_basic.py` from previous homework, make sure to not overwrite the `BatchNorm2d` module."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbqLiefzY1mh"
      },
      "source": [
        "### Padding ndarrays\n",
        "\n",
        "Convolution as typically implemented in deep learning libraries cuts down the size of inputs;\n",
        "e.g., a (1, 32, 32, 3) image convolved with a 3x3 filter would give a (1, 30, 30, c) output.\n",
        "A way around this is to pad the input ndarray before performing convolution, e.g., pad with zeros to get a (1, 34, 34, 3) ndarray so that the result is (1, 32, 32, 3).\n",
        "\n",
        "Padding is also required for the backward pass of convolution.\n",
        "\n",
        "You should implement `pad` in `ndarray.py` to closely reflect the behavior of `np.pad`.\n",
        "That is, `pad` should take a tuple of 2-tuples with length equal to the number of dimensions of the array,\n",
        "where each element in the 2-tuple corresponds to \"left padding\" and \"right padding\", respectively.\n",
        "\n",
        "For example, if `A` is a (10, 32, 32, 8) ndarray (think NHWC), then `A.pad( (0, 0), (2, 2), (2, 2), (0, 0) )` would be a (10, 36, 36, 8) ndarray where the \"spatial\" dimension has been padded by two zeros on all sides."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdlsWzCzY1mh"
      },
      "outputs": [],
      "source": [
        "!python3 -m pytest -l -v -k \"pad_forward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QfmjJK9Y1mh"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKbnVBEVY1mh"
      },
      "source": [
        "### Flipping ndarrays & FlipOp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1e7mMVJzY1mh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import ctypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "an6Ae_jxY1mh"
      },
      "source": [
        "Some utility code for a demonstration below which you can probably ignore. It might be instructive to check out the `offset` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-qNcbI7Y1mh"
      },
      "outputs": [],
      "source": [
        "# reads off the underlying data array in order (i.e., offset 0, offset 1, ..., offset n)\n",
        "# i.e., ignoring strides\n",
        "def raw_data(X):\n",
        "    X = np.array(X) # copy, thus compact X\n",
        "    return np.frombuffer(ctypes.string_at(X.ctypes.data, X.nbytes), dtype=X.dtype, count=X.size)\n",
        "\n",
        "# Xold and Xnew should reference the same underlying data\n",
        "def offset(Xold, Xnew):\n",
        "    assert Xold.itemsize == Xnew.itemsize\n",
        "    # compare addresses to the beginning of the arrays\n",
        "    return (Xnew.ctypes.data - Xold.ctypes.data)//Xnew.itemsize\n",
        "\n",
        "def strides(X):\n",
        "    return ', '.join([str(x//X.itemsize) for x in X.strides])\n",
        "\n",
        "def format_array(X, shape):\n",
        "    assert len(shape) == 3, \"I only made this formatting work for ndims = 3\"\n",
        "    def chunks(l, n):\n",
        "        n = max(1, n)\n",
        "        return (l[i:i+n] for i in range(0, len(l), n))\n",
        "    a = [str(x) if x >= 10 else ' ' + str(x) for x in X]\n",
        "    a = ['(' + ' '.join(y) + ')' for y in [x for x in chunks(a, shape[-1])]]\n",
        "    a = ['|' + ' '.join(y) + '|' for y in [x for x in chunks(a, shape[-2])]]\n",
        "    return '  '.join(a)\n",
        "\n",
        "def inspect_array(X, *, is_a_copy_of):\n",
        "    # compacts X, then reads it off in order\n",
        "    print('Data: %s' % format_array(raw_data(X), X.shape))\n",
        "    # compares address of X to copy_of, thus finding X's offset\n",
        "    print('Offset: %s' % offset(is_a_copy_of, X))\n",
        "    print('Strides: %s' % strides(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "lAdNXN9UY1mi"
      },
      "source": [
        "In order to implement the backwards pass of 2D convolution, we will (probably) need a function which _flips_\n",
        "axes of ndarrays. We say \"probably\" because you could probably cleverly implement your convolution forward\n",
        "function to avoid this. However, we think it is easiest to think about this if you have the ability to \"flip\" the kernel along its vertical and horizontal dimensions.\n",
        "\n",
        "We will try to build up your intuition for the \"flip\" operation below in order to help you figure out how to implement it in `ndarray.py`. To do that, we explore numpy's `np.flip` function below. One thing to note is that\n",
        "`flip` is typically implemented by using negative strides and changing the _offset_ of the underlying array.\n",
        "\n",
        "For example, flipping an array on _all_ of its axes is equivalent to reversing the array. In this case, you can imagine that we would want all the strides to be negative, and the offset to be the length of the array (to start at the end of the array and \"stride\" backwards).\n",
        "\n",
        "Since we did not explicitly support negative strides in our implementation for the last homework, we will merely call `NDArray.make` with them to make our \"flipped\" array and then immediately call `.compact()`. Other than changing unsigned ints to signed ints in a few places, we suspect your existing `compact` function should not have to change at all to accomodate negative strides. In the .cc and .cu files we distributed, we have already changed the function signatures to reflect this.\n",
        "\n",
        "Alternatively, you could simply implement `flip` in the CPU backend by copying memory, which you _may_ find more intuitive. We suggest following our mini tutorial below to keep your implementation Python-focused, since we believe it is involves approximately the same amount of effort to implement it slightly more naively in C."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmEgFYB8Y1mi"
      },
      "source": [
        "Use this array as reference for the other examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2cRsOBPY1mi"
      },
      "outputs": [],
      "source": [
        "A = np.arange(1, 25).reshape(3, 2, 4)\n",
        "inspect_array(A, is_a_copy_of=A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHwySIF8Y1mi"
      },
      "source": [
        "We have put brackets around each axis of the array. Notice that for this array, the offset is 0 and the strides are all positive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrWAflboY1mi"
      },
      "source": [
        "----------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2DRvY-ZY1mi"
      },
      "source": [
        "See what happens when you flip the array along the last axis below.\n",
        "Note that the `inspect_array` function compacts the array after flipping it so you can see the\n",
        "\"logical\" order of the data, and the offset is calculated by comparing the address of the **non**-compacted\n",
        "flipped array with that of `is_copy_of`, i.e., the array `A` we looked at above.\n",
        "\n",
        "That is, we are looking at how numpy calculates the strides and offset for flipped arrays in order\n",
        "to copy this behavior in our own implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PV1VRqsY1mi"
      },
      "outputs": [],
      "source": [
        "inspect_array(np.flip(A, (2,)), is_a_copy_of=A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsCrq8anY1mi"
      },
      "source": [
        "So flipping the last axis reverses the order of the elements within each 4-dimensional \"cell\", as you can see above. The stride corresponding to the axis we flipped has been negated. And the offset is 3 -- this makes sense, e.g., because we want the new \"first\" element of the array to be 4, which was at index 3 in `A`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLftb_0dY1mi"
      },
      "outputs": [],
      "source": [
        "inspect_array(np.flip(A, (1,)), is_a_copy_of=A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMzO5-S6Y1mi"
      },
      "source": [
        "Again for the middle axis: we negate the middle stride, and the offset is 4, which seems reasonable since we now want the first element to be 5, which was at index 4 in the original array `A`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McLVBz21Y1mi"
      },
      "outputs": [],
      "source": [
        "inspect_array(np.flip(A, (0,)), is_a_copy_of=A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAthxAcvY1mi"
      },
      "source": [
        "Try to infer the more general algorithm for computing the offset given the axis to flip."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sp9Olp_HY1mi"
      },
      "source": [
        "----------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tWw3gRaY1mi"
      },
      "source": [
        "Observe what happens when we flip _all_ axes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMCu_P8dY1mj"
      },
      "outputs": [],
      "source": [
        "inspect_array(np.flip(A, (0, 1, 2)), is_a_copy_of=A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geZsA6d_Y1mj"
      },
      "source": [
        "As mentioned earlier, the offset is then sufficient to point to the last element of the array, and this is just the \"reverse order\" version of `A`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoixN5fpY1mj"
      },
      "source": [
        "When we flip just axes 1 and 0..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx9uX_OOY1mj"
      },
      "outputs": [],
      "source": [
        "inspect_array(np.flip(A, (0, 1)), is_a_copy_of=A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwscsygXY1mo"
      },
      "source": [
        "The offset is 20. Looking back on our previous offset computations, do you notice something?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B7FmkHNY1mo"
      },
      "source": [
        "-------------------\n",
        "\n",
        "With this exploration of numpy's ndarray flipping functionality, which uses negative strides and a custom offset,\n",
        "try to implement `flip` in `ndarray.py`. You also must implement \"flip\" forward and backward functions in `ops_mathematic.py`; note that these should be extremely short.\n",
        "\n",
        "**Important:** You should call NDArray.make with the new strides and offset, and then immediately `.compact()` this array. The resulting array is then copied and has positive strides. We want this (less-than-optimal) behavior because we did not account for negative strides in our previous implementation. _Aside:_ If you want, consider where/if negative strides break your implementation. `__getitem__` definitely doesn't work due to how we processed slices; is there anything else? (_Note_: this isn't graded.)\n",
        "\n",
        "Also, if you want to add a `flip` operator implementation on the CPU/CUDA backends instead, that's also okay.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VL-QkxatY1mo"
      },
      "outputs": [],
      "source": [
        "!python3 -m pytest -l -v -k \"flip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wingqoOY1mo"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTB53evoY1mp"
      },
      "source": [
        "### Dilation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKA0LflyY1mp"
      },
      "source": [
        "The dilation operator puts zeros between elements of an ndarray. We will need it for computing the backward pass of convolution when the stride of the convolution is greater than 1. As an example, dilation should do the following to a 2x2 matrix when dilated by 1 on both axes:\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "1 & 2 \\\\\n",
        "3 & 4\n",
        "\\end{bmatrix}\n",
        "\\Longrightarrow\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & 2 & 0 \\\\\n",
        "0 & 0 & 0 & 0 \\\\\n",
        "3 & 0 & 4 & 0 \\\\\n",
        "0 & 0 & 0 & 0\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "To get some intuition for why we need dilation for the backward pass of strided convolution, consider a  `stride=2`, `padding=\"same\"`, `input_channels=output_channels=8` convolution applied to an input of size (10, 32, 32, 8). The resulting output will be of size (10, 16, 16, 8) due to the stride, and thus `out_grad` will have shape (10, 16, 16, 8). Yet, the gradient of the input needs to, of course, have shape (10, 32, 32, 8) -- so we must need to increase the size of `out_grad` in some way. Consider also that you could implement strided convolution as `Conv(x)[:, ::2, ::2, :]`, i.e., only keeping every other pixel in the spatial dimension.\n",
        "\n",
        "\n",
        "Implement `Dilate` and `UnDilate` in `ops_mathematic.py`. Each operator takes two additional parameters (in attrs): the `dilation` amount and the `axes` to dilate. You must also implement the corresponding op `UnDilate`, whose forward pass will be used to implement the gradient of `Dilate`. (This is so we do not have to implement `GetItem` and `SetItem` ops, which can be highly inefficient to backprop through without additional optimizations.)\n",
        "\n",
        "**Note**: The dilation amount is additive, not multiplicative. In the example above, a dilation of `1` implies adding one row/column of zeros between each element along each dilated axis (and one removed row/column for each undilated axis). A dilation of `0` means no change."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFwQ2F25Y1mp"
      },
      "outputs": [],
      "source": [
        "!python3 -m pytest -l -v -k \"dilate\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRhKs2DDY1mp"
      },
      "source": [
        "---------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIALlOacY1mp"
      },
      "source": [
        "### Submit new ops (flip/dilation) to mugrade [10 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZtb545DY1mp"
      },
      "outputs": [],
      "source": [
        "!python3 -m mugrade submit \"YOUR KEY HERE\" -k \"new_ops\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QirnB7RY1mp"
      },
      "source": [
        "-----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgnm8j-nY1mp"
      },
      "source": [
        "### Convolution forward\n",
        "\n",
        "Implement the forward pass of 2D multi-channel convolution in `ops_mathematic.py`. You should probably refer to [this notebook](https://github.com/dlsyscourse/public_notebooks/blob/main/convolution_implementation.ipynb) from lecture, which implements 2D multi-channel convolution using im2col in numpy.\n",
        "\n",
        "**Note:** Your convolution op should accept tensors in the NHWC format, as in the example above, and weights in the format (kernel_size, kernel_size, input_channels, output_channels).\n",
        "\n",
        "However, you will need to add two additional features. Your convolution function should accept arguments for `padding` (default 0) and `stride` (default 1). For `padding`, you should simply apply your padding function to the spatial dimensions (i.e., axes 1 and 2).\n",
        "\n",
        "Implementing strided convolution should consist of a relatively small set of changes to your plain convolution implementation.\n",
        "\n",
        "We recommend working your way up through the full feature set: Implement convolution without stride first, ensuring you pass some of the tests below, and then add in support for stride."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LveCTS4Y1mp"
      },
      "outputs": [],
      "source": [
        "!python3 -m pytest -l -v -k \"op_conv and forward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72IO8meGY1mp"
      },
      "source": [
        "-----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOsRkVFuY1mp"
      },
      "source": [
        "### Convolution backward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2IuG_LyY1mp"
      },
      "source": [
        "Finding the gradients of 2D multi-channel convolution can be technically quite challenging (especially \"rigorously\"). We will try to provide some useful hints here. Basically, we encourage you to make use of the surprising fact that _whatever makes the dimensions work out is typically right_.\n",
        "\n",
        "Ultimately, the backward pass of convolution can be done in terms of the convolution operator itself, with some clever manipulations using `flip`, `dilate`, and multiple applications of `transpose` to both the arguments and the results.\n",
        "\n",
        "In the last section, we essentially implemented convolution as a matrix product: ignoring the various restride and reshape operations, we basically have something like `X @ W`, where `X` is the input and `W` is the weight. We also have `out_grad`, which is the same shape as `X @ W`. Now, you have already implemented the backward pass of matrix multiplication in a previous assignment, and we can use this knowledge to get some insight into the backward pass of convolution. In particular, referencing your matmul backward implementation, you may notice (heuristically speaking here):\n",
        "\n",
        "`X.grad = out_grad @ W.transpose` \\\n",
        "`W.grad = X.transpose @ out_grad`\n",
        "\n",
        "Surprisingly enough, things work out if we just assume that these are also convolutions (and now assuming that `out_grad`, `W`, and `X` are tensors amenable to 2D multi-channel convolution instead of matrices):\n",
        "\n",
        "`X.grad = ≈conv(≈out_grad, ≈W)` \\\n",
        "`W.grad = ≈conv(≈X, ≈out_grad)`\n",
        "\n",
        "In which the \"≈\" indicates that you need to apply some additional operators to these terms in order to get the dimensions to work out, such as permuting/transposing axes, dilating, changing the `padding=` argument to the convolution function, or permuting/transposing axes of the resulting convolution.\n",
        "\n",
        "As we saw on the [last few slides here](https://dlsyscourse.org/slides/conv_nets.pdf) in class, the transpose of a convolution can be found by simply flipping the kernel. Since we're working in 2D instead of 1D, this means flipping the kernel both vertically and horizontally (thus why we implemented `flip`).\n",
        "\n",
        "Summarizing some hints for both `X.grad` and `W.grad`:\n",
        "\n",
        "`X.grad`\n",
        "- The convolution of `out_grad` and `W`, with some operations applied to those\n",
        "- `W` should be flipped over both the kernel dimensions\n",
        "- If the convolution is strided, increase the size of `out_grad` with a corresponding dilation\n",
        "- Do an example to analyze dimensions: note the shape you want for `X.grad`, and think about how you must permute/transpose the arguments and add padding to the convolution to achieve this shape\n",
        "    - This padding depends on both the kernel size and the `padding` argument to the convolution\n",
        "\n",
        "`W.grad`\n",
        "- The convolution of `X` and `out_grad`, with some operations applied to those\n",
        "- The gradients of `W` must be accumulated over the batches; how can you make the conv operator itself do this accumulation?\n",
        "    - Consider turning batches into channels via transpose/permute\n",
        "- Analyze dimensions: how can you modify `X` and `out_grad` so that the shape of their convolution matches the shape of `W`? You may need to transpose/permute the result.\n",
        "    - Remember to account for the `padding` argument passed to convolution\n",
        "\n",
        "General tips\n",
        "- Deal with strided convolutions last (you should be able to just drop in `dilate` when you've passed most of the tests)\n",
        "- Start with the case where `padding=0`, then consider changing `padding` arguments\n",
        "- You can \"permute\" axes with multiple calls to `transpose`\n",
        "\n",
        "It might also be useful to skip ahead to nn.Conv, pass the forward tests, and then use both the tests below and the nn.Conv backward tests to debug your implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3IRGy0DY1mq"
      },
      "outputs": [],
      "source": [
        "!python3 -m pytest -l -v -k \"op_conv and backward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YloMCt2EY1mq"
      },
      "source": [
        "-----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyWhYKULY1mq"
      },
      "source": [
        "### nn.Conv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "nf0OGhbCY1mq"
      },
      "source": [
        "#### Fixing init._calculate_fans for convolution\n",
        "Previously, we have implemented Kaiming uniform/normal initializations, where we essentially assigned `fan_in = input_size` and `fan_out = output_size`.\n",
        "For convolution, this becomes somewhat more detailed, in that you should multiply both of these by the \"receptive field size\", which is in this case just the product of the kernel sizes -- which in our case are always going to be the same, i.e., $k\\times k$ kernels.\n",
        "\n",
        "**You will need to edit your `kaiming_uniform` in `python/needle/init/init_initializers.py`, etc. init functions to support multidimensional arrays.** In particular, it should support a new `shape` argument which is then passed to, e.g., the underlying `rand` function. Specifically, if the argument `shape` is not `None`, then ignore `fan_in` and `fan_out`, and use the value of `shape` for initializations instead.\n",
        "\n",
        "You can test this below; though it is not _directly_ graded, it must match ours to pass the nn.Conv mugrade tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJbCzGWmY1mq"
      },
      "outputs": [],
      "source": [
        "!python3 -m pytest -l -v -k \"kaiming_uniform\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfVlPl38Y1mq"
      },
      "source": [
        "#### Implementing nn.Conv\n",
        "\n",
        "Essentially, nn.Conv is just a wrapper of the convolution operator we previously implemented\n",
        "which adds a bias term, initializes the weight and bias, and ensures that the padding is set so that the input and output dimensions are the same (in the `stride=1` case, anyways).\n",
        "\n",
        "Importantly, nn.Conv should support NCHW format instead of NHWC format. In particular, we think this makes more sense given our current BatchNorm implementation. You can implement this by applying `transpose` twice to both the input and output.  \n",
        "\n",
        "- Ensure nn.Conv works for `(N, C, H, W)` tensors even though we implemented the conv op for `(N, H, W, C)` tensors\n",
        "- Initialize the `(k, k, i, o)` weight tensor using Kaiming uniform initialization with default settings\n",
        "- Initialize the `(o,)` bias tensor using uniform initialization on the interval $\\displaystyle\\pm\\frac{1}{\\sqrt{\\verb|in_channels| \\times \\verb|kernel_size|^2}}$\n",
        "- Calculate the appropriate padding to ensure input and output dimensions are the same\n",
        "- Calculate the convolution, then add the properly-broadcasted bias term if present\n",
        "\n",
        "You can now test your nn.Conv against PyTorch's nn.Conv2d with the two PyTest calls below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezzxaG6VY1mq"
      },
      "outputs": [],
      "source": [
        "!python3 -m pytest -l -v -k \"nn_conv_forward\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ESjRBzUY1mq"
      },
      "outputs": [],
      "source": [
        "!python3 -m pytest -l -v -k \"nn_conv_backward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEdL4tryY1mq"
      },
      "source": [
        "-----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKhl27IAY1mq"
      },
      "source": [
        "### Submit nn.Conv to mugrade [20 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81R9L1s_Y1mq"
      },
      "outputs": [],
      "source": [
        "!python3 -m mugrade submit \"YOUR KEY HERE\" -k \"conv_forward\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeqMLrmCY1mq"
      },
      "outputs": [],
      "source": [
        "!python3 -m mugrade submit \"YOUR KEY HERE\" -k \"conv_backward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sb8jkpPY1mq"
      },
      "source": [
        "------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "euoAmR71Y1mq"
      },
      "source": [
        "### Implementing \"ResNet9\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfFz8tMSY1mr"
      },
      "source": [
        "You will now use your convolutional layer to implement a model similar to _ResNet9_, which is known to be a reasonable model for getting good accuracy on CIFAR-10 quickly (see [here](https://github.com/davidcpage/cifar10-fast)). Our main change is that we used striding instead of pooling and divided all of the channels by 4 for the sake of performance (as our framework is not as well-optimized as industry-grade frameworks).\n",
        "\n",
        "In the figure below, before the first linear layer, you should \"flatten\" the tensor. You can use the module `Flatten` in `nn_basic.py`, or you can simply use `.reshape` in the `forward()` method of your ResNet9.\n",
        "\n",
        "Make sure that you pass the device to all modules in your model; otherwise, you will get errors about mismatched devices when trying to run with CUDA.\n",
        "\n",
        "<center><img src=\"https://github.com/dlsyscourse/hw4/blob/main/ResNet9.png?raw=true\" alt=\"ResNet9\" style=\"width: 400px;\" /></center>\n",
        "\n",
        "We have tried to make it easier to pass the tests here than for previous assignments where you have implemented models. In particular, we are just going to make sure it has the right number of parameters and similar accuracy and loss after 1 or 2 batches of CIFAR-10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpVqgX80Y1mr",
        "outputId": "c793316e-aa26-4d58-9518-2dfc4c7058f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: typeguard-4.4.1, anyio-3.7.1\n",
            "collected 1803 items / 1801 deselected / 2 selected                                                \u001b[0m\n",
            "\n",
            "tests/hw4/test_conv.py::test_resnet9[needle.backend_ndarray.ndarray_backend_cpu] \u001b[32mPASSED\u001b[0m\u001b[32m      [ 50%]\u001b[0m\n",
            "tests/hw4/test_conv.py::test_resnet9[needle.backend_ndarray.ndarray_backend_cuda] \u001b[32mPASSED\u001b[0m\u001b[32m     [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m=============================== \u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m1801 deselected\u001b[0m\u001b[32m in 16.21s\u001b[0m\u001b[32m ================================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"resnet9\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk7DxUT3Y1mr"
      },
      "source": [
        "Now we can train a ResNet on CIFAR10: (remember to copy the solutions in `python/needle/optim.py` from previous homeworks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eRsVKwQY1mr"
      },
      "outputs": [],
      "source": [
        "!python3 -m pytest -l -v -k \"train_cifar10\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVYOZppdY1mr"
      },
      "source": [
        "### Submit ResNet9 to mugrade [10 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyHoYbucY1mr"
      },
      "outputs": [],
      "source": [
        "!python3 -m mugrade submit \"YOUR KEY HERE\" -k \"resnet9\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW-lhbT-Y1mr"
      },
      "source": [
        "-----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nu9xrkzkY1mr"
      },
      "source": [
        "Now, you can train your model on CIFAR-10 using the following code. Note that this is likely going to be quite slow, and also  not all that accurate due to the lack of data augmentation. You should expect it to take around 500s per epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUMc0I20Y1mr"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('./python')\n",
        "sys.path.append('./apps')\n",
        "import needle as ndl\n",
        "from models import ResNet9\n",
        "from simple_ml import train_cifar10, evaluate_cifar10\n",
        "\n",
        "device = ndl.cpu()\n",
        "dataset = ndl.data.CIFAR10Dataset(\"data/cifar-10-batches-py\", train=True)\n",
        "dataloader = ndl.data.DataLoader(\\\n",
        "         dataset=dataset,\n",
        "         batch_size=128,\n",
        "         shuffle=True,)\n",
        "model = ResNet9(device=device, dtype=\"float32\")\n",
        "train_cifar10(model, dataloader, n_epochs=10, optimizer=ndl.optim.Adam,\n",
        "      lr=0.001, weight_decay=0.001)\n",
        "evaluate_cifar10(model, dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTlv9wH2Y1mr"
      },
      "source": [
        "## Part 4: Recurrent neural network [10 points]\n",
        "\n",
        "**Note:** In the following sections, you may find yourself wanting to index into tensors, i.e., to use getitem or setitem. However, we have not implemented these for tensors in our library; instead, you should use `stack` and `split` operations.\n",
        "\n",
        "In `python/needle/nn_sequence.py`, implement `RNNCell`.\n",
        "\n",
        "$h^\\prime = \\text{tanh}(xW_{ih} + b_{ih} + hW_{hh} + b_{hh})$. If nonlinearity is 'relu', then ReLU is used in place of tanh.\n",
        "\n",
        "All weights and biases should be uniformly initialized on the interval $\\displaystyle\\pm\\frac{1}{\\sqrt{\\verb|hidden_size|}}$.\n",
        "\n",
        "In `python/needle/nn_sequence.py`, implement `RNN`.\n",
        "\n",
        "For each element in the input sequence, each layer computes the following function:\n",
        "\n",
        "$h_t = \\text{tanh}(x_tW_{ih} + b_{ih} + h_{(t-1)}W_{hh} + b_{hh})$\n",
        "\n",
        "where $h_t$ is the hidden state at time $t$, $x_t$ is the input at time $t$, and $h_{(t-1)}$ is the hidden state of the previous layer at time $t-1$ or the initial hidden state at time $0$. If nonlinearity is 'relu', then ReLU is used in place of tanh.\n",
        "\n",
        "In a multi-layer RNN, the input $x_t^{(l)}$ of the $l$-th layer ($l \\ge 2$) is the hidden state $h_t^{(l-1)}$ of the previous layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5g-58sP4Y1mr",
        "outputId": "165b8518-100f-47fd-fe78-6c19f3956285"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "        [-1.1468363 ],\n",
            "        [-0.03207249]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956cc45e0>, array([[[0.        , 0.        , 0.        , 0.       ...        0.        , 0.        , 0.8024849 , 0.4938322 , 0.13574998,\n",
            "         0.        , 0.21632192]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 209 / 360 (58.1%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 0.91467273\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 6.595441\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.152725, 0.      , 0.114764, 0.      , 0.23143 , 0.069926],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.      , 0.      , 1.075149, 0.456447, 0.665768, 0.      ,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.      , 0.      , 0.      , 0.      , 0.246647, 0.197586,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.      , 0.392719, 0.087152, 0.      , 0.      , 0.      ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.203462, 0.      , 0.807231, 0.963306, 1.096821, 0.      ,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956cc45e0>, array([[[0.        , 0.        , 0.        , 0.       ...        0.        , 0.        , 0.8024849 , 0.4938322 , 0.13574998,\n",
            "         0.        , 0.21632192]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m____________________________ test_rnn[cuda-relu-True-True-12-1-15-2-13] ____________________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 2, batch_size = 15, input_size = 1, hidden_size = 12, bias = True\n",
            "init_hidden = True, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[3.81863713e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "   0.00000000e+00 2.31180966e-01 0.000000...000e+00 8.54113027e-02 0.00000000e+00 7.08078593e-03\n",
            "   4.18709517e-02 0.00000000e+00 9.22907591e-02 0.00000000e+00]]])\n",
            "h0         = array([[[-2.25707963e-01,  5.73837399e-01, -2.96123475e-01,\n",
            "          8.71669352e-01, -1.48400962e+00,  4.40479457e-01..., -5.67049623e-01, -2.26908505e-01,\n",
            "          1.32712138e+00,  6.19198442e-01,  1.71096611e+00]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[0.0000, 0.2137, 0.4521, 0.1130, 0.0000, 0.1690, 0.1626, 0.0000,\n",
            "          0.0371, 0.1325, 0.0000, 0.0000],\n",
            " ... 0.0000, 0.0000, 0.0532, 0.0000, 0.4918, 0.0000,\n",
            "          0.0000, 0.2501, 0.3533, 0.1454]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = True\n",
            "input_size = 1\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a3956ffe710>\n",
            "model_     = RNN(1, 12, num_layers=2)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[0.44237688 1.2293067  0.         ... 0.7281687  0.18477717 0.        ]\n",
            "  [0.         0.         0.607...9433 ... 0.         0.09243026 0.        ]\n",
            "  [0.         0.         0.15102604 ... 0.         0.09229076 0.        ]]])\n",
            "output_    = tensor([[[0.5583, 1.7791, 0.0000,  ..., 1.0341, 0.3190, 0.0000],\n",
            "         [0.0000, 0.3422, 0.2838,  ..., 0.3294, 0.099...8, 0.3251, 0.1250],\n",
            "         [0.0555, 0.1306, 0.0000,  ..., 0.2501, 0.3533, 0.1454]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[-9.2837501e-01],\n",
            "        [-1.0556091e+00],\n",
            "        [ 1.2465471e+00],\n",
            "        [ 3.3251369e-01],\n",
            "        [ 9.27...       [ 1.1842438e+00],\n",
            "        [ 8.6801094e-01],\n",
            "        [ 6.2654391e-02],\n",
            "        [ 3.8579333e-01]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956cc4f70>, array([[[0.        , 0.2136569 , 0.4521221 , 0.1130209...e+00, 7.08078593e-03,\n",
            "         4.18709517e-02, 0.00000000e+00, 9.22907591e-02, 0.00000000e+00]]],\n",
            "      dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 300 / 360 (83.3%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 0.56610274\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 600.27826\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.      , 0.213657, 0.452122, 0.113021, 0.      , 0.169004,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.162574, 0.      , 0.037071, 0.132472, 0.      , 0.      ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.      , 0.243523, 0.612959, 0.      , 0.      , 0.016213,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[3.818637e-02, 0.000000e+00, 0.000000e+00, 0.000000e+00,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.000000e+00, 2.311810e-01, 0.000000e+00, 4.212486e-01,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.000000e+00, 2.289088e-01, 0.000000e+00, 0.000000e+00],...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956cc4f70>, array([[[0.        , 0.2136569 , 0.4521221 , 0.1130209...e+00, 7.08078593e-03,\n",
            "         4.18709517e-02, 0.00000000e+00, 9.22907591e-02, 0.00000000e+00]]],\n",
            "      dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m____________________________ test_rnn[cuda-relu-True-True-12-11-1-1-1] _____________________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 1, batch_size = 1, input_size = 11, hidden_size = 12, bias = True\n",
            "init_hidden = True, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.6846003  0.         0.26748684 1.1111745  0.24888879 0.7125596\n",
            "   1.9422436  0.31909427 0.         0.53967726 0.         0.83676094]]])\n",
            "h0         = array([[[ 2.0021796 ,  0.06810276, -0.00210566,  0.35923558,\n",
            "         -0.53881186,  0.6595335 , -0.69113183,  0.09069487,\n",
            "         -0.47788447,  0.2162854 , -0.728331  ,  0.79294884]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[0.7932, 0.0000, 0.0000, 0.8332, 0.7129, 0.3920, 2.7026, 0.8374,\n",
            "          0.3366, 0.7759, 0.0000, 1.0792]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = True\n",
            "input_size = 11\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a39571cbdf0>\n",
            "model_     = RNN(11, 12)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[0.6846003  0.         0.26748684 1.1111745  0.24888879 0.7125596\n",
            "   1.9422436  0.31909427 0.         0.53967726 0.         0.83676094]]])\n",
            "output_    = tensor([[[0.7932, 0.0000, 0.0000, 0.8332, 0.7129, 0.3920, 2.7026, 0.8374,\n",
            "          0.3366, 0.7759, 0.0000, 1.0792]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[ 0.3148921 , -1.1125008 ,  0.66214556,  1.3619871 ,\n",
            "         -0.9441923 ,  0.07119288, -1.4503505 , -0.79636693,\n",
            "         -0.39230755,  1.0963713 ,  1.8753006 ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a395712c940>, array([[[0.7931854 , 0.        , 0.        , 0.8332305...        0.7125596 , 1.9422436 , 0.31909427, 0.        , 0.53967726,\n",
            "         0.        , 0.83676094]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 10 / 12 (83.3%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 0.76031876\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 1.8641775\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.793185, 0.      , 0.      , 0.83323 , 0.712862, 0.391955,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    2.702562, 0.837426, 0.336585, 0.775875, 0.      , 1.079182]]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                 dtype=float32)\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.6846  , 0.      , 0.267487, 1.111174, 0.248889, 0.71256 ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    1.942244, 0.319094, 0.      , 0.539677, 0.      , 0.836761]]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                 dtype=float32)\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a395712c940>, array([[[0.7931854 , 0.        , 0.        , 0.8332305...        0.7125596 , 1.9422436 , 0.31909427, 0.        , 0.53967726,\n",
            "         0.        , 0.83676094]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m____________________________ test_rnn[cuda-relu-True-True-12-11-1-1-13] ____________________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 1, batch_size = 1, input_size = 11, hidden_size = 12, bias = True\n",
            "init_hidden = True, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.         0.         1.497879   0.23629361 0.91204476 1.308697\n",
            "   0.         0.         0.         0.         0.38677073 0.        ]]])\n",
            "h0         = array([[[ 0.36780962,  1.0061082 , -0.392694  , -0.60835296,\n",
            "         -1.2271525 ,  2.024626  ,  0.25878015,  1.0139538 ,\n",
            "          0.94182175,  1.2013899 ,  1.3891249 , -0.98686033]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[0.0000, 0.0000, 1.3071, 0.6641, 0.0000, 0.4331, 0.0000, 0.0023,\n",
            "          0.0000, 0.0000, 0.1834, 0.0000]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = True\n",
            "input_size = 11\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a3977511fc0>\n",
            "model_     = RNN(11, 12)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[0.         0.         1.2906411  0.         0.         0.\n",
            "   0.         0.         0.16259342 0.64168...     1.497879   0.23629361 0.91204476 1.308697\n",
            "   0.         0.         0.         0.         0.38677073 0.        ]]])\n",
            "output_    = tensor([[[0.0000, 0.0000, 1.1615, 0.0000, 0.0000, 0.0000, 0.0057, 0.0000,\n",
            "          0.1064, 1.3916, 0.0000, 0.6259]],\n",
            "... 1.3071, 0.6641, 0.0000, 0.4331, 0.0000, 0.0023,\n",
            "          0.0000, 0.0000, 0.1834, 0.0000]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[-0.8298414 ,  1.0821636 ,  0.7433526 , -1.3383278 ,\n",
            "          2.2646353 , -0.7023059 ,  1.3251851 , -0.362038...  -0.58566064, -0.20258886,  1.8392947 , -0.9646667 ,\n",
            "         -1.3837264 ,  1.1144935 , -0.6241543 ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956e26cb0>, array([[[0.        , 0.        , 1.3070661 , 0.6641376...        1.308697  , 0.        , 0.        , 0.        , 0.        ,\n",
            "         0.38677073, 0.        ]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 6 / 12 (50%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 0.91204476\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 1.8106456\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.      , 0.      , 1.307066, 0.664138, 0.      , 0.433053,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.      , 0.002334, 0.      , 0.      , 0.18339 , 0.      ]]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                 dtype=float32)\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.      , 0.      , 1.497879, 0.236294, 0.912045, 1.308697,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.      , 0.      , 0.      , 0.      , 0.386771, 0.      ]]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                 dtype=float32)\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956e26cb0>, array([[[0.        , 0.        , 1.3070661 , 0.6641376...        1.308697  , 0.        , 0.        , 0.        , 0.        ,\n",
            "         0.38677073, 0.        ]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m____________________________ test_rnn[cuda-relu-True-True-12-11-1-2-1] _____________________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 2, batch_size = 1, input_size = 11, hidden_size = 12, bias = True\n",
            "init_hidden = True, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.         0.         0.         1.720892   0.         0.6657312\n",
            "   0.58939147 0.         0.         ...8  0.         0.         1.0341897  0.23016053\n",
            "   0.         0.28491715 0.         0.         1.2242812  0.        ]]])\n",
            "h0         = array([[[-1.3397268 ,  0.7845705 ,  0.6561998 , -0.5114237 ,\n",
            "         -0.8611901 , -0.02471994, -0.42867446,  0.287370...30714  ,  0.77552503, -0.31661543,\n",
            "          0.04133654,  0.93658847, -1.3398391 ,  0.42262155]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[0.0000, 0.0000, 0.0000, 1.7487, 0.5986, 0.7722, 1.2318, 0.0000,\n",
            "          0.0000, 0.0000, 0.1886, 0.4216]],\n",
            "... 0.0000, 0.0000, 0.3939, 0.0000, 0.0000, 0.5915,\n",
            "          0.0000, 0.0000, 0.8053, 0.0000]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = True\n",
            "input_size = 11\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a3956fd2da0>\n",
            "model_     = RNN(11, 12, num_layers=2)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[0.08912057 1.1754798  0.         0.         1.0341897  0.23016053\n",
            "   0.         0.28491715 0.         0.         1.2242812  0.        ]]])\n",
            "output_    = tensor([[[0.0000, 1.0836, 0.0000, 0.0000, 0.3939, 0.0000, 0.0000, 0.5915,\n",
            "          0.0000, 0.0000, 0.8053, 0.0000]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[-0.67132443, -0.47733116,  0.7809086 ,  1.3375176 ,\n",
            "          1.0982716 , -2.8556044 , -0.80699015, -1.4077936 ,\n",
            "         -0.49352673, -2.9539716 , -0.0458057 ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956e27e20>, array([[[0.        , 0.        , 0.        , 1.7486689...        0.23016053, 0.        , 0.28491715, 0.        , 0.        ,\n",
            "         1.2242812 , 0.        ]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 12 / 24 (50%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 0.6424552\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 1.0900314\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.      , 0.      , 0.      , 1.748669, 0.598568, 0.772202,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    1.231847, 0.      , 0.      , 0.      , 0.188595, 0.42155 ]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE           ...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.      , 0.      , 0.      , 1.720892, 0.      , 0.665731,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.589391, 0.      , 0.      , 0.      , 0.      , 0.      ]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE           ...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956e27e20>, array([[[0.        , 0.        , 0.        , 1.7486689...        0.23016053, 0.        , 0.28491715, 0.        , 0.        ,\n",
            "         1.2242812 , 0.        ]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m____________________________ test_rnn[cuda-relu-True-True-12-11-1-2-13] ____________________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 2, batch_size = 1, input_size = 11, hidden_size = 12, bias = True\n",
            "init_hidden = True, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.0000000e+00 1.3106300e-01 8.9941752e-01 1.2244333e-01 7.2151423e-04\n",
            "   0.0000000e+00 4.7135270e-01 ...0000000e+00\n",
            "   1.7624974e-01 0.0000000e+00 0.0000000e+00 1.1697307e-01 3.3165848e-01\n",
            "   2.8979552e-01 3.3295155e-02]]])\n",
            "h0         = array([[[-0.3057115 ,  0.6663601 ,  1.6317247 ,  0.2491036 ,\n",
            "          0.24976106,  1.0958275 , -1.5904077 , -0.108989...406688 , -0.14347358,  0.3612032 ,\n",
            "         -0.38831314,  1.4344796 ,  0.18403931, -0.90633255]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[0.1915, 0.0000, 0.6484, 0.0000, 0.2504, 0.0000, 0.3386, 0.0000,\n",
            "          0.0000, 0.2230, 0.2105, 0.0000]],\n",
            "... 0.2015, 0.0509, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.3224, 0.0000, 0.4693, 0.0000]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = True\n",
            "input_size = 11\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a3956bc8e80>\n",
            "model_     = RNN(11, 12, num_layers=2)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[0.         0.20361781 0.23409545 0.86525655 0.06282958 0.88168263\n",
            "   1.0796154  0.         1.001461  ...45 0.59973407 0.12439424 0.         0.17624974\n",
            "   0.         0.         0.11697307 0.33165848 0.28979552 0.03329515]]])\n",
            "output_    = tensor([[[0.0000, 0.5496, 0.0000, 0.8334, 0.1304, 0.7243, 1.3340, 0.0000,\n",
            "          0.9616, 1.2964, 0.9354, 0.7794]],\n",
            "... 0.2015, 0.0509, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.3224, 0.0000, 0.4693, 0.0000]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[ 0.46689013, -1.112396  ,  0.33066764, -1.8420694 ,\n",
            "         -0.10290266,  0.86394936,  0.30298376,  1.009665...   0.96759623,  0.942517  ,  0.9157867 ,  0.09240709,\n",
            "         -0.9563757 ,  0.44699663, -0.27808407]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956cc41f0>, array([[[0.19147596, 0.        , 0.6484361 , 0.       ...00000e+00, 0.0000000e+00,\n",
            "         1.1697307e-01, 3.3165848e-01, 2.8979552e-01, 3.3295155e-02]]],\n",
            "      dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 19 / 24 (79.2%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 0.7205117\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 346.04288\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.191476, 0.      , 0.648436, 0.      , 0.250396, 0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.338615, 0.      , 0.      , 0.222967, 0.210475, 0.      ]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE           ...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.000000e+00, 1.310630e-01, 8.994175e-01, 1.224433e-01,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    7.215142e-04, 0.000000e+00, 4.713527e-01, 0.000000e+00,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    4.031611e-01, 9.434791e-01, 7.699036e-01, 4.998005e-01]],...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956cc41f0>, array([[[0.19147596, 0.        , 0.6484361 , 0.       ...00000e+00, 0.0000000e+00,\n",
            "         1.1697307e-01, 3.3165848e-01, 2.8979552e-01, 3.3295155e-02]]],\n",
            "      dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m____________________________ test_rnn[cuda-relu-True-True-12-11-15-1-1] ____________________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 1, batch_size = 15, input_size = 11, hidden_size = 12, bias = True\n",
            "init_hidden = True, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.         0.4853511  0.         0.41860095 0.51035905 0.\n",
            "   0.6055988  0.         0.         0.     ...1.4951851  0.1829666  0.84858906 0.87473685 0.\n",
            "   0.37063625 0.15158117 0.4289609  0.9135033  0.7108575  0.        ]]])\n",
            "h0         = array([[[-1.9369982 , -0.5263702 , -0.44775727,  0.13298298,\n",
            "         -0.534451  , -0.00705814, -1.2415073 , -1.150344...574494 , -1.8785205 , -0.07056727,\n",
            "          0.35366735,  1.2517182 , -0.7339186 , -1.0909673 ]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[0.0000, 0.6842, 0.0000, 0.9069, 0.0000, 0.0000, 0.5159, 0.0000,\n",
            "          0.0000, 0.0000, 0.6636, 0.0000],\n",
            " ... 0.5964, 1.3369, 0.2174, 0.0000, 0.2810, 0.3984,\n",
            "          0.8724, 0.0469, 0.6647, 0.0000]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = True\n",
            "input_size = 11\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a3956e3ed70>\n",
            "model_     = RNN(11, 12)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[0.         0.4853511  0.         0.41860095 0.51035905 0.\n",
            "   0.6055988  0.         0.         0.     ...1.4951851  0.1829666  0.84858906 0.87473685 0.\n",
            "   0.37063625 0.15158117 0.4289609  0.9135033  0.7108575  0.        ]]])\n",
            "output_    = tensor([[[0.0000, 0.6842, 0.0000, 0.9069, 0.0000, 0.0000, 0.5159, 0.0000,\n",
            "          0.0000, 0.0000, 0.6636, 0.0000],\n",
            " ... 0.5964, 1.3369, 0.2174, 0.0000, 0.2810, 0.3984,\n",
            "          0.8724, 0.0469, 0.6647, 0.0000]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[ 0.39451045,  1.0946134 ,  0.4080253 , -0.18793328,\n",
            "          0.9515867 ,  0.00557369,  0.20007043,  0.909105...  -1.292069  ,  0.4641795 ,  0.37550968,  1.6048833 ,\n",
            "         -1.4211361 , -0.06844403, -1.7508378 ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956cc4700>, array([[[0.        , 0.684197  , 0.        , 0.9068656...        0.        , 0.37063625, 0.15158117, 0.4289609 , 0.9135033 ,\n",
            "         0.7108575 , 0.        ]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 98 / 180 (54.4%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 0.86660576\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 7.5076094\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.      , 0.684197, 0.      , 0.906866, 0.      , 0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.515918, 0.      , 0.      , 0.      , 0.663575, 0.      ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.225816, 1.061065, 0.      , 0.      , 0.257559, 0.361956,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.      , 0.485351, 0.      , 0.418601, 0.510359, 0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.605599, 0.      , 0.      , 0.      , 0.709744, 0.      ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.      , 0.862219, 0.      , 0.      , 0.914855, 0.      ,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956cc4700>, array([[[0.        , 0.684197  , 0.        , 0.9068656...        0.        , 0.37063625, 0.15158117, 0.4289609 , 0.9135033 ,\n",
            "         0.7108575 , 0.        ]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m___________________________ test_rnn[cuda-relu-True-True-12-11-15-1-13] ____________________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 1, batch_size = 15, input_size = 11, hidden_size = 12, bias = True\n",
            "init_hidden = True, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.2822016  0.7206564  0.         0.12801665 1.2526988  0.20673761\n",
            "   0.         0.         0.8690521 ...667 1.0570282  0.0435935  0.23222356 1.7739434\n",
            "   0.7288408  0.         0.         0.5673477  0.         0.        ]]])\n",
            "h0         = array([[[ 6.41118944e-01,  2.22184634e+00,  3.26699972e-01,\n",
            "          9.25458312e-01,  7.70667866e-02,  5.58315516e-01...,  2.97930866e-01,  1.40280151e+00,\n",
            "         -1.22370809e-01, -2.38177085e+00,  9.49312985e-01]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[0.4534, 0.2233, 0.0000, 0.1923, 0.5933, 0.3266, 0.0000, 0.0000,\n",
            "          0.7288, 0.1813, 0.0000, 0.0000],\n",
            " ... 1.3044, 0.1815, 0.0000, 1.9571, 0.0000, 0.0000,\n",
            "          0.0000, 0.1554, 0.0000, 0.0000]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = True\n",
            "input_size = 11\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a3956d66c80>\n",
            "model_     = RNN(11, 12)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[0.00000000e+00 1.47681582e+00 2.83501565e-01 ... 1.15718126e+00\n",
            "   0.00000000e+00 0.00000000e+00]\n",
            "  [...0.00000000e+00]\n",
            "  [4.45145071e-01 1.28426671e-01 1.05702817e+00 ... 5.67347705e-01\n",
            "   0.00000000e+00 0.00000000e+00]]])\n",
            "output_    = tensor([[[0.0000, 1.1384, 0.6581,  ..., 0.9343, 0.0000, 0.0000],\n",
            "         [0.3319, 0.0000, 0.5823,  ..., 1.3841, 0.508...0, 0.0000, 0.0000],\n",
            "         [0.5671, 0.0000, 1.3044,  ..., 0.1554, 0.0000, 0.0000]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[ 0.51831853,  0.12550014,  0.4947879 , ...,  0.6376503 ,\n",
            "          1.8797847 ,  0.7121892 ],\n",
            "        [ 0.3450...\n",
            "        [-1.2339394 , -1.5977813 , -1.659676  , ...,  1.494589  ,\n",
            "          0.92649287,  0.77399164]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956cc64d0>, array([[[0.45343298, 0.22329628, 0.        , 0.1922935...        1.7739434 , 0.7288408 , 0.        , 0.        , 0.5673477 ,\n",
            "         0.        , 0.        ]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 107 / 180 (59.4%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 1.2928996\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 4.9568343\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.453433, 0.223296, 0.      , 0.192294, 0.593332, 0.326594,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.      , 0.      , 0.728815, 0.181317, 0.      , 0.      ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.      , 0.      , 0.      , 0.200771, 0.      , 0.353932,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.282202, 0.720656, 0.      , 0.128017, 1.252699, 0.206738,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.      , 0.      , 0.869052, 0.558264, 0.      , 0.      ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.      , 0.      , 0.      , 0.330514, 0.      , 0.168446,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956cc64d0>, array([[[0.45343298, 0.22329628, 0.        , 0.1922935...        1.7739434 , 0.7288408 , 0.        , 0.        , 0.5673477 ,\n",
            "         0.        , 0.        ]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m____________________________ test_rnn[cuda-relu-True-True-12-11-15-2-1] ____________________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 2, batch_size = 15, input_size = 11, hidden_size = 12, bias = True\n",
            "init_hidden = True, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[7.11779475e-01 3.06963921e-05 1.08337998e-01 0.00000000e+00\n",
            "   4.58600402e-01 0.00000000e+00 6.834000...000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "   1.99215084e-01 0.00000000e+00 1.79053688e+00 1.03560627e-01]]])\n",
            "h0         = array([[[-1.12526429e+00,  1.03048837e+00,  1.59768045e+00,\n",
            "          4.89892922e-02,  1.32837379e+00,  7.32201114e-02...,  8.85597765e-01, -9.47140932e-01,\n",
            "          7.10499585e-01, -5.35180151e-01, -9.53392744e-01]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[0.3978, 0.0000, 0.0000, 0.0000, 0.3832, 0.0000, 0.3009, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.8630],\n",
            " ... 0.6136, 0.0000, 0.0000, 0.0000, 0.0000, 0.0496,\n",
            "          0.5848, 0.0000, 1.6230, 0.0000]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = True\n",
            "input_size = 11\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a395726efe0>\n",
            "model_     = RNN(11, 12, num_layers=2)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[6.10549212e-01 1.47765899e+00 0.00000000e+00 0.00000000e+00\n",
            "   3.64118606e-01 1.05681419e-01 1.444649...000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "   1.99215084e-01 0.00000000e+00 1.79053688e+00 1.03560627e-01]]])\n",
            "output_    = tensor([[[0.5093, 1.1056, 0.0000, 0.0613, 0.8530, 0.0000, 0.0000, 0.9463,\n",
            "          0.0396, 0.0000, 0.0000, 0.0000],\n",
            " ... 0.6136, 0.0000, 0.0000, 0.0000, 0.0000, 0.0496,\n",
            "          0.5848, 0.0000, 1.6230, 0.0000]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[ 8.96971405e-01,  1.50723362e+00,  2.45223016e-01,\n",
            "         -1.51116729e+00, -7.14914441e-01,  8.95351350e-01...         1.03263509e+00, -1.92010343e+00,  8.56736481e-01,\n",
            "         -1.05208433e+00,  1.02227926e+00]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956cc6dd0>, array([[[0.39779025, 0.        , 0.        , 0.       ...e+00, 0.00000000e+00,\n",
            "         1.99215084e-01, 0.00000000e+00, 1.79053688e+00, 1.03560627e-01]]],\n",
            "      dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 195 / 360 (54.2%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 0.7533355\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 96.71507\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.39779 , 0.      , 0.      , 0.      , 0.383231, 0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.300914, 0.      , 0.      , 0.      , 0.      , 0.863013],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.521483, 0.      , 0.      , 0.549329, 0.120204, 0.641296,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[7.117795e-01, 3.069639e-05, 1.083380e-01, 0.000000e+00,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    4.586004e-01, 0.000000e+00, 6.834000e-03, 0.000000e+00,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.000000e+00, 0.000000e+00, 0.000000e+00, 8.482176e-01],...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956cc6dd0>, array([[[0.39779025, 0.        , 0.        , 0.       ...e+00, 0.00000000e+00,\n",
            "         1.99215084e-01, 0.00000000e+00, 1.79053688e+00, 1.03560627e-01]]],\n",
            "      dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m___________________________ test_rnn[cuda-relu-True-True-12-11-15-2-13] ____________________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 2, batch_size = 15, input_size = 11, hidden_size = 12, bias = True\n",
            "init_hidden = True, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.26453805 0.         0.         0.         0.         0.972701\n",
            "   0.         0.         0.15112713 0...87 0.         0.28209886 0.6823096  0.32340157\n",
            "   0.         0.05475053 0.28002793 0.         0.3033948  0.        ]]])\n",
            "h0         = array([[[ 4.62617099e-01, -8.73586893e-01,  3.95268232e-01,\n",
            "          2.22453028e-01,  9.46717262e-01,  9.90536392e-01...,  1.06370699e+00, -2.50244308e+00,\n",
            "         -2.33064580e+00,  3.55511427e-01,  1.33337355e+00]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[0.3822, 0.0000, 0.0000, 0.0000, 0.0000, 0.2603, 0.0000, 0.0000,\n",
            "          0.5339, 0.0000, 0.0000, 0.1514],\n",
            " ... 0.0000, 0.0093, 0.0287, 0.0000, 0.0000, 0.4613,\n",
            "          0.0000, 0.0000, 0.3308, 0.0000]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = True\n",
            "input_size = 11\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a39573495a0>\n",
            "model_     = RNN(11, 12, num_layers=2)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[0.         0.6490415  0.         ... 0.         0.38383144 0.        ]\n",
            "  [0.         0.7712692  0.   ...     ... 0.16966923 0.52192545 0.        ]\n",
            "  [0.         0.10148387 0.         ... 0.         0.3033948  0.        ]]])\n",
            "output_    = tensor([[[0.0000, 0.5768, 0.7444,  ..., 0.0000, 0.1802, 0.0000],\n",
            "         [0.2434, 1.1333, 0.1018,  ..., 0.3128, 1.127...6, 0.4539, 0.0000],\n",
            "         [0.0000, 0.0952, 0.0000,  ..., 0.0000, 0.3308, 0.0000]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[-1.04204881e+00, -7.74658084e-01,  9.33664106e-03, ...,\n",
            "         -9.84409928e-01,  2.21479368e+00, -2.9483322...18117440e+00,  4.47466552e-01, ...,\n",
            "          3.55011612e-01, -8.68709028e-01, -5.44773102e-01]]],\n",
            "      dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956cc76d0>, array([[[0.38216782, 0.        , 0.        , 0.       ...        0.32340157, 0.        , 0.05475053, 0.28002793, 0.        ,\n",
            "         0.3033948 , 0.        ]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 226 / 360 (62.8%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 1.1028997\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 44.806534\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.382168, 0.      , 0.      , 0.      , 0.      , 0.260335,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.      , 0.      , 0.533886, 0.      , 0.      , 0.151408],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.126628, 0.      , 0.700128, 0.      , 0.      , 0.      ,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.264538, 0.      , 0.      , 0.      , 0.      , 0.972701,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.      , 0.      , 0.151127, 0.      , 0.      , 0.      ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.012808, 0.      , 0.248486, 0.      , 0.      , 0.369131,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956cc76d0>, array([[[0.38216782, 0.        , 0.        , 0.       ...        0.32340157, 0.        , 0.05475053, 0.28002793, 0.        ,\n",
            "         0.3033948 , 0.        ]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m_____________________________ test_rnn[cuda-relu-False-True-1-1-1-1-1] _____________________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 1, batch_size = 1, input_size = 1, hidden_size = 1, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[1.7298427]]])\n",
            "h0         = array([[[0.19343226]]], dtype=float32)\n",
            "h_         = tensor([[[0.4123]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a3956cf9030>\n",
            "model_     = RNN(1, 1)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[1.7298427]]])\n",
            "output_    = tensor([[[0.4123]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[0.2518457]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956cc5000>, array([[[0.41230193]]], dtype=float32), array([[[1.7298427]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 1 / 1 (100%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 1.3175408\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 0.76165354\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.412302]]], dtype=float32)\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[1.729843]]], dtype=float32)\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956cc5000>, array([[[0.41230193]]], dtype=float32), array([[[1.7298427]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m_____________________________ test_rnn[cuda-relu-False-True-1-1-1-2-1] _____________________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 2, batch_size = 1, input_size = 1, hidden_size = 1, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.21436095]]\n",
            "\n",
            " [[0.        ]]])\n",
            "h0         = array([[[ 0.4488501]],\n",
            "\n",
            "       [[-0.6718067]]], dtype=float32)\n",
            "h_         = tensor([[[3.2285]],\n",
            "\n",
            "        [[1.2429]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a3956cf6620>\n",
            "model_     = RNN(1, 1, num_layers=2)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[0.]]])\n",
            "output_    = tensor([[[1.2429]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[-1.7255726]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956b744c0>, array([[[3.2285001]],\n",
            "\n",
            "       [[1.2429104]]], dtype=float32), array([[[0.21436095]],\n",
            "\n",
            "       [[0.        ]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 2 / 2 (100%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 3.0141392\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 14.061046\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[3.2285 ]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [[1.24291]]], dtype=float32)\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.214361]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [[0.      ]]], dtype=float32)\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956b744c0>, array([[[3.2285001]],\n",
            "\n",
            "       [[1.2429104]]], dtype=float32), array([[[0.21436095]],\n",
            "\n",
            "       [[0.        ]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m____________________________ test_rnn[cuda-relu-False-True-1-1-1-2-13] _____________________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 2, batch_size = 1, input_size = 1, hidden_size = 1, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[4.7747126]]\n",
            "\n",
            " [[0.       ]]])\n",
            "h0         = array([[[-0.46471584]],\n",
            "\n",
            "       [[-0.00578226]]], dtype=float32)\n",
            "h_         = tensor([[[3.3956]],\n",
            "\n",
            "        [[0.0000]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a3956c38070>\n",
            "model_     = RNN(1, 1, num_layers=2)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[0.8103194 ]]\n",
            "\n",
            " [[0.53390074]]\n",
            "\n",
            " [[0.7598938 ]]\n",
            "\n",
            " [[0.4124781 ]]\n",
            "\n",
            " [[0.2282303 ]]\n",
            "\n",
            " [[0.        ]]\n",
            "\n",
            " [[0.        ]]\n",
            "\n",
            " [[0.        ]]\n",
            "\n",
            " [[0.        ]]\n",
            "\n",
            " [[0.        ]]\n",
            "\n",
            " [[0.        ]]\n",
            "\n",
            " [[0.        ]]\n",
            "\n",
            " [[0.        ]]])\n",
            "output_    = tensor([[[0.5887]],\n",
            "\n",
            "        [[0.3524]],\n",
            "\n",
            "        [[0.6181]],\n",
            "\n",
            "        [[0.3085]],\n",
            "\n",
            "        [[0.1601]],\n",
            "\n",
            "        [[0.0....0000]],\n",
            "\n",
            "        [[0.0000]],\n",
            "\n",
            "        [[0.0000]],\n",
            "\n",
            "        [[0.0000]],\n",
            "\n",
            "        [[0.0000]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[ 0.13484336]],\n",
            "\n",
            "       [[ 0.5600182 ]],\n",
            "\n",
            "       [[-1.3608078 ]],\n",
            "\n",
            "       [[ 0.8305043 ]],\n",
            "\n",
            "       [[ 0.251251...]],\n",
            "\n",
            "       [[ 0.13382451]],\n",
            "\n",
            "       [[-0.88616496]],\n",
            "\n",
            "       [[-0.34309512]],\n",
            "\n",
            "       [[-0.09963788]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956b74ee0>, array([[[3.3955827]],\n",
            "\n",
            "       [[0.       ]]], dtype=float32), array([[[4.7747126]],\n",
            "\n",
            "       [[0.       ]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 1 / 2 (50%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 1.3791299\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 0.2888404\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[3.395583]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [[0.      ]]], dtype=float32)\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[4.774713]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [[0.      ]]], dtype=float32)\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956b74ee0>, array([[[3.3955827]],\n",
            "\n",
            "       [[0.       ]]], dtype=float32), array([[[4.7747126]],\n",
            "\n",
            "       [[0.       ]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m____________________________ test_rnn[cuda-relu-False-True-1-1-15-1-1] _____________________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 1, batch_size = 15, input_size = 1, hidden_size = 1, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]])\n",
            "h0         = array([[[-0.30352262],\n",
            "        [-0.16265571],\n",
            "        [-0.28750268],\n",
            "        [-0.74471074],\n",
            "        [-2.3090835 ],\n",
            "   ...5737146 ],\n",
            "        [-1.5683346 ],\n",
            "        [ 0.91853374],\n",
            "        [ 0.97419107],\n",
            "        [-0.7149789 ]]], dtype=float32)\n",
            "h_         = tensor([[[0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [0.1988],\n",
            "         [0.0000],\n",
            "    ...      [0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a3956c007c0>\n",
            "model_     = RNN(1, 1)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]])\n",
            "output_    = tensor([[[0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [0.1988],\n",
            "         [0.0000],\n",
            "    ...      [0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[ 0.06657807],\n",
            "        [-0.897686  ],\n",
            "        [-0.6754    ],\n",
            "        [ 2.0090454 ],\n",
            "        [-1.4515733 ],\n",
            "   ...28355804],\n",
            "        [ 0.5181106 ],\n",
            "        [ 1.6374208 ],\n",
            "        [-0.41069183],\n",
            "        [ 0.6578221 ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956b75480>, array([[[0.        ],\n",
            "        [0.        ],\n",
            "        [0....],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 1 / 15 (6.67%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 0.19875395\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: inf\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.      ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.      ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.      ],...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.],...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956b75480>, array([[[0.        ],\n",
            "        [0.        ],\n",
            "        [0....],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m____________________________ test_rnn[cuda-relu-False-True-1-1-15-1-13] ____________________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 1, batch_size = 15, input_size = 1, hidden_size = 1, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.60168624]\n",
            "  [0.70181733]\n",
            "  [1.0687034 ]\n",
            "  [1.2038753 ]\n",
            "  [1.182989  ]\n",
            "  [0.7844585 ]\n",
            "  [1.0088739 ]...0.17353225]\n",
            "  [0.65867054]\n",
            "  [1.5394241 ]\n",
            "  [1.4137435 ]\n",
            "  [1.3297582 ]\n",
            "  [1.3406487 ]\n",
            "  [0.99355835]\n",
            "  [0.01655507]]])\n",
            "h0         = array([[[-0.9467423 ],\n",
            "        [ 1.0618031 ],\n",
            "        [ 0.41449785],\n",
            "        [ 0.4079134 ],\n",
            "        [-1.054843  ],\n",
            "   ...8432862 ],\n",
            "        [-0.8666433 ],\n",
            "        [-0.5033698 ],\n",
            "        [ 1.7010827 ],\n",
            "        [ 0.9928533 ]]], dtype=float32)\n",
            "h_         = tensor([[[0.1088],\n",
            "         [0.2182],\n",
            "         [0.5758],\n",
            "         [0.7110],\n",
            "         [0.6901],\n",
            "         [0.2916],\n",
            "    ...      [0.9226],\n",
            "         [0.8369],\n",
            "         [0.8486],\n",
            "         [0.5007],\n",
            "         [0.0000]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a3956ab2440>\n",
            "model_     = RNN(1, 1)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[1.8722018 ]\n",
            "  [1.783921  ]\n",
            "  [1.3196343 ]\n",
            "  [0.905404  ]\n",
            "  [0.8147639 ]\n",
            "  [1.954282  ]\n",
            "  [1.0876563 ]...0.17353225]\n",
            "  [0.65867054]\n",
            "  [1.5394241 ]\n",
            "  [1.4137435 ]\n",
            "  [1.3297582 ]\n",
            "  [1.3406487 ]\n",
            "  [0.99355835]\n",
            "  [0.01655507]]])\n",
            "output_    = tensor([[[1.1869],\n",
            "         [1.0986],\n",
            "         [0.6343],\n",
            "         [0.2201],\n",
            "         [0.1294],\n",
            "         [1.2689],\n",
            "    ...      [0.9226],\n",
            "         [0.8369],\n",
            "         [0.8486],\n",
            "         [0.5007],\n",
            "         [0.0000]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[-1.5497485 ],\n",
            "        [-1.259353  ],\n",
            "        [ 0.26789564],\n",
            "        [ 1.6304861 ],\n",
            "        [ 1.9286424 ],\n",
            "   ...7188151 ],\n",
            "        [-0.8976141 ],\n",
            "        [-0.5375709 ],\n",
            "        [-0.18112764],\n",
            "        [ 2.751154  ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956e24790>, array([[[0.10879841],\n",
            "        [0.21815866],\n",
            "        [0...[1.4137435 ],\n",
            "        [1.3297582 ],\n",
            "        [1.3406487 ],\n",
            "        [0.99355835],\n",
            "        [0.01655507]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 15 / 15 (100%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 0.49304152\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 1.\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.108798],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.218159],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.575815],...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.601686],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.701817],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [1.068703],...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956e24790>, array([[[0.10879841],\n",
            "        [0.21815866],\n",
            "        [0...[1.4137435 ],\n",
            "        [1.3297582 ],\n",
            "        [1.3406487 ],\n",
            "        [0.99355835],\n",
            "        [0.01655507]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m____________________________ test_rnn[cuda-relu-False-True-1-1-15-2-1] _____________________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 2, batch_size = 15, input_size = 1, hidden_size = 1, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.11239046]\n",
            "  [1.3573754 ]\n",
            "  [1.0159404 ]\n",
            "  [1.9685094 ]\n",
            "  [0.09189248]\n",
            "  [1.0662289 ]\n",
            "  [1.0115913 ]...1.158114  ]\n",
            "  [1.6888843 ]\n",
            "  [1.059475  ]\n",
            "  [1.1403704 ]\n",
            "  [0.931774  ]\n",
            "  [1.5992064 ]\n",
            "  [1.8174099 ]\n",
            "  [0.9871013 ]]])\n",
            "h0         = array([[[ 0.16324045],\n",
            "        [ 0.7679383 ],\n",
            "        [ 1.9964887 ],\n",
            "        [-0.03845823],\n",
            "        [ 0.75351495],\n",
            "   ...1890684 ],\n",
            "        [ 0.5114554 ],\n",
            "        [-1.1488643 ],\n",
            "        [-0.02941375],\n",
            "        [-0.2401329 ]]], dtype=float32)\n",
            "h_         = tensor([[[0.7153],\n",
            "         [1.9602],\n",
            "         [1.6188],\n",
            "         [2.5714],\n",
            "         [0.6948],\n",
            "         [1.6691],\n",
            "    ...      [0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a3956bf47c0>\n",
            "model_     = RNN(1, 1, num_layers=2)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[1.7728667 ]\n",
            "  [0.96598804]\n",
            "  [1.1872731 ]\n",
            "  [0.56991005]\n",
            "  [1.7861516 ]\n",
            "  [1.154681  ]\n",
            "  [1.1900918 ]...1.158114  ]\n",
            "  [1.6888843 ]\n",
            "  [1.059475  ]\n",
            "  [1.1403704 ]\n",
            "  [0.931774  ]\n",
            "  [1.5992064 ]\n",
            "  [1.8174099 ]\n",
            "  [0.9871013 ]]])\n",
            "output_    = tensor([[[0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.]...,\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[ 1.4122152 ],\n",
            "        [-1.2166817 ],\n",
            "        [-0.49571142],\n",
            "        [-2.507146  ],\n",
            "        [ 1.4554986 ],\n",
            "   ...64852566],\n",
            "        [-1.3281546 ],\n",
            "        [ 0.84641147],\n",
            "        [ 1.5573415 ],\n",
            "        [-1.1478926 ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956e27eb0>, array([[[0.71526176],\n",
            "        [1.9602467 ],\n",
            "        [1...[1.1403704 ],\n",
            "        [0.931774  ],\n",
            "        [1.5992064 ],\n",
            "        [1.8174099 ],\n",
            "        [0.9871013 ]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 30 / 30 (100%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 1.8174099\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 13.807666\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.715262],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [1.960247],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [1.618812],...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.11239 ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [1.357375],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [1.01594 ],...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956e27eb0>, array([[[0.71526176],\n",
            "        [1.9602467 ],\n",
            "        [1...[1.1403704 ],\n",
            "        [0.931774  ],\n",
            "        [1.5992064 ],\n",
            "        [1.8174099 ],\n",
            "        [0.9871013 ]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m____________________________ test_rnn[cuda-relu-False-True-1-1-15-2-13] ____________________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 2, batch_size = 15, input_size = 1, hidden_size = 1, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.        ]\n",
            "  [0.073429  ]\n",
            "  [0.22110054]\n",
            "  [0.        ]\n",
            "  [0.5995396 ]\n",
            "  [0.13484606]\n",
            "  [0.05715267]...0.00904822]\n",
            "  [0.        ]\n",
            "  [0.01091786]\n",
            "  [0.00904822]\n",
            "  [0.00904822]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]])\n",
            "h0         = array([[[-0.870247  ],\n",
            "        [-1.218556  ],\n",
            "        [-1.2616584 ],\n",
            "        [-1.0489405 ],\n",
            "        [ 0.8601348 ],\n",
            "   ...6097364 ],\n",
            "        [-0.00257094],\n",
            "        [-1.2489376 ],\n",
            "        [-0.32111347],\n",
            "        [-0.77329296]]], dtype=float32)\n",
            "h_         = tensor([[[0.7309],\n",
            "         [0.9457],\n",
            "         [0.8595],\n",
            "         [0.6280],\n",
            "         [1.5144],\n",
            "         [1.0419],\n",
            "    ...      [0.6578],\n",
            "         [0.6767],\n",
            "         [0.2851],\n",
            "         [0.3328],\n",
            "         [0.2596]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a395706eb90>\n",
            "model_     = RNN(1, 1, num_layers=2)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[0.00904822]\n",
            "  [0.00904822]\n",
            "  [0.00904822]\n",
            "  [0.00904822]\n",
            "  [0.        ]\n",
            "  [0.00904822]\n",
            "  [0.        ]...0.00904822]\n",
            "  [0.        ]\n",
            "  [0.01091786]\n",
            "  [0.00904822]\n",
            "  [0.00904822]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]])\n",
            "output_    = tensor([[[0.7893],\n",
            "         [0.9233],\n",
            "         [0.8414],\n",
            "         [0.9756],\n",
            "         [0.5897],\n",
            "         [1.0439],\n",
            "    ...      [0.6578],\n",
            "         [0.6767],\n",
            "         [0.2851],\n",
            "         [0.3328],\n",
            "         [0.2596]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[ 0.29415044],\n",
            "        [ 0.814208  ],\n",
            "        [ 0.49644375],\n",
            "        [ 1.0168548 ],\n",
            "        [-0.48005575],\n",
            "   ...91404146],\n",
            "        [ 1.982717  ],\n",
            "        [-0.6508447 ],\n",
            "        [ 0.4759155 ],\n",
            "        [-0.02764585]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956e27b50>, array([[[0.73086447],\n",
            "        [0.9456854 ],\n",
            "        [0...[0.00904822],\n",
            "        [0.00904822],\n",
            "        [0.        ],\n",
            "        [0.        ],\n",
            "        [0.        ]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 29 / 30 (96.7%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 1.1152047\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 102.14495\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.730864],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.945685],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.85949 ],...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.      ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.073429],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.221101],...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956e27b50>, array([[[0.73086447],\n",
            "        [0.9456854 ],\n",
            "        [0...[0.00904822],\n",
            "        [0.00904822],\n",
            "        [0.        ],\n",
            "        [0.        ],\n",
            "        [0.        ]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m____________________________ test_rnn[cuda-relu-False-True-1-11-1-1-13] ____________________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 1, batch_size = 1, input_size = 11, hidden_size = 1, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(output_.detach().numpy(), output.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.]]])\n",
            "h0         = array([[[0.0284506]]], dtype=float32)\n",
            "h_         = tensor([[[0.]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a3956c24f70>\n",
            "model_     = RNN(11, 1)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[0.10325539]]\n",
            "\n",
            " [[0.        ]]\n",
            "\n",
            " [[0.        ]]\n",
            "\n",
            " [[0.        ]]\n",
            "\n",
            " [[0.        ]]\n",
            "\n",
            " [[0.        ]]\n",
            "\n",
            " [[0.        ]]\n",
            "\n",
            " [[1.039535  ]]\n",
            "\n",
            " [[0.        ]]\n",
            "\n",
            " [[0.        ]]\n",
            "\n",
            " [[0.        ]]\n",
            "\n",
            " [[0.        ]]\n",
            "\n",
            " [[0.        ]]])\n",
            "output_    = tensor([[[1.6988]],\n",
            "\n",
            "        [[0.0000]],\n",
            "\n",
            "        [[0.0000]],\n",
            "\n",
            "        [[0.0000]],\n",
            "\n",
            "        [[0.0000]],\n",
            "\n",
            "        [[0.0....0000]],\n",
            "\n",
            "        [[1.0548]],\n",
            "\n",
            "        [[0.0000]],\n",
            "\n",
            "        [[1.1926]],\n",
            "\n",
            "        [[0.0000]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[-0.02388999,  0.12719929,  3.1143436 ,  0.96135443,\n",
            "          0.8620496 ,  0.4742671 , -0.2972879 , -0.580824...  -1.651972  ,  1.100938  ,  0.52573705, -0.3064305 ,\n",
            "          0.00514151, -0.26271677,  1.6562326 ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:135: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956cc55a0>, array([[[1.6988071 ]],\n",
            "\n",
            "       [[0.        ]],\n",
            "\n",
            "      ...   ]],\n",
            "\n",
            "       [[0.        ]],\n",
            "\n",
            "       [[0.        ]],\n",
            "\n",
            "       [[0.        ]],\n",
            "\n",
            "       [[0.        ]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 5 / 13 (38.5%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 1.5955517\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 15.452478\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[1.698807]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [[0.      ]],...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.103255]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [[0.      ]],...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956cc55a0>, array([[[1.6988071 ]],\n",
            "\n",
            "       [[0.        ]],\n",
            "\n",
            "      ...   ]],\n",
            "\n",
            "       [[0.        ]],\n",
            "\n",
            "       [[0.        ]],\n",
            "\n",
            "       [[0.        ]],\n",
            "\n",
            "       [[0.        ]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m____________________________ test_rnn[cuda-relu-False-True-1-11-1-2-13] ____________________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 2, batch_size = 1, input_size = 11, hidden_size = 1, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.]]\n",
            "\n",
            " [[0.]]])\n",
            "h0         = array([[[ 1.0097189]],\n",
            "\n",
            "       [[-1.0484025]]], dtype=float32)\n",
            "h_         = tensor([[[0.0000]],\n",
            "\n",
            "        [[0.3529]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a3956e5ac20>\n",
            "model_     = RNN(11, 1, num_layers=2)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[0.]]\n",
            "\n",
            " [[0.]]\n",
            "\n",
            " [[0.]]\n",
            "\n",
            " [[0.]]\n",
            "\n",
            " [[0.]]\n",
            "\n",
            " [[0.]]\n",
            "\n",
            " [[0.]]\n",
            "\n",
            " [[0.]]\n",
            "\n",
            " [[0.]]\n",
            "\n",
            " [[0.]]\n",
            "\n",
            " [[0.]]\n",
            "\n",
            " [[0.]]\n",
            "\n",
            " [[0.]]])\n",
            "output_    = tensor([[[0.0000]],\n",
            "\n",
            "        [[0.0000]],\n",
            "\n",
            "        [[0.3529]],\n",
            "\n",
            "        [[0.2004]],\n",
            "\n",
            "        [[0.0000]],\n",
            "\n",
            "        [[0.0....0000]],\n",
            "\n",
            "        [[0.0000]],\n",
            "\n",
            "        [[0.3529]],\n",
            "\n",
            "        [[0.0000]],\n",
            "\n",
            "        [[0.3529]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[ 0.04708548, -2.4136145 ,  0.60610384, -1.2147981 ,\n",
            "         -0.10475262, -1.228351  ,  0.07251215, -0.911447...   1.7286403 , -0.17758673,  0.28982943, -0.5293846 ,\n",
            "          0.54758376,  0.35235903,  1.4279629 ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956cc4040>, array([[[0.       ]],\n",
            "\n",
            "       [[0.3529296]]], dtype=float32), array([[[0.]],\n",
            "\n",
            "       [[0.]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 1 / 2 (50%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 0.3529296\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: inf\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.     ]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [[0.35293]]], dtype=float32)\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE                  [[0.]]], dtype=float32)\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956cc4040>, array([[[0.       ]],\n",
            "\n",
            "       [[0.3529296]]], dtype=float32), array([[[0.]],\n",
            "\n",
            "       [[0.]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m____________________________ test_rnn[cuda-relu-False-True-1-11-15-1-1] ____________________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 1, batch_size = 15, input_size = 11, hidden_size = 1, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.      ]\n",
            "  [0.      ]\n",
            "  [0.      ]\n",
            "  [0.      ]\n",
            "  [0.      ]\n",
            "  [0.      ]\n",
            "  [0.      ]\n",
            "  [4.16749 ]\n",
            "  [0.      ]\n",
            "  [0.      ]\n",
            "  [0.759506]\n",
            "  [0.      ]\n",
            "  [0.      ]\n",
            "  [0.      ]\n",
            "  [0.      ]]])\n",
            "h0         = array([[[-0.35362   ],\n",
            "        [-1.9190978 ],\n",
            "        [-1.7959664 ],\n",
            "        [ 1.0522387 ],\n",
            "        [ 0.72194695],\n",
            "   ...2972703 ],\n",
            "        [ 0.3724343 ],\n",
            "        [ 0.90110886],\n",
            "        [-0.5699806 ],\n",
            "        [-1.2025036 ]]], dtype=float32)\n",
            "h_         = tensor([[[0.4536],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [0.1150],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "    ...      [1.8100],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a3956feb0d0>\n",
            "model_     = RNN(11, 1)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[0.      ]\n",
            "  [0.      ]\n",
            "  [0.      ]\n",
            "  [0.      ]\n",
            "  [0.      ]\n",
            "  [0.      ]\n",
            "  [0.      ]\n",
            "  [4.16749 ]\n",
            "  [0.      ]\n",
            "  [0.      ]\n",
            "  [0.759506]\n",
            "  [0.      ]\n",
            "  [0.      ]\n",
            "  [0.      ]\n",
            "  [0.      ]]])\n",
            "output_    = tensor([[[0.4536],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [0.1150],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "    ...      [1.8100],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[ 0.17617291,  0.80040145,  0.63351846,  1.6805384 ,\n",
            "          0.24284601,  0.04403457,  1.7149817 ,  0.668840...   0.6329303 ,  0.60805404, -1.2787381 , -2.4096363 ,\n",
            "          0.26784697,  0.6193943 , -0.42702177]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956cc5480>, array([[[0.45364854],\n",
            "        [0.        ],\n",
            "        [0...,\n",
            "        [0.759506],\n",
            "        [0.      ],\n",
            "        [0.      ],\n",
            "        [0.      ],\n",
            "        [0.      ]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 4 / 15 (26.7%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 1.0505047\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 1.3831421\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.453649],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.      ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.      ],...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.      ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.      ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.      ],...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956cc5480>, array([[[0.45364854],\n",
            "        [0.        ],\n",
            "        [0...,\n",
            "        [0.759506],\n",
            "        [0.      ],\n",
            "        [0.      ],\n",
            "        [0.      ],\n",
            "        [0.      ]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m___________________________ test_rnn[cuda-relu-False-True-1-11-15-1-13] ____________________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 1, batch_size = 15, input_size = 11, hidden_size = 1, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.        ]\n",
            "  [0.        ]\n",
            "  [0.12066683]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [2.0379133 ]\n",
            "  [0.        ]...0.        ]\n",
            "  [0.        ]\n",
            "  [2.3002307 ]\n",
            "  [1.9830031 ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [2.331148  ]\n",
            "  [1.2269504 ]]])\n",
            "h0         = array([[[ 0.01461633],\n",
            "        [ 1.2894311 ],\n",
            "        [ 0.4298501 ],\n",
            "        [-1.0609628 ],\n",
            "        [-1.258269  ],\n",
            "   ...6120253 ],\n",
            "        [-0.0521547 ],\n",
            "        [-0.48247576],\n",
            "        [-0.26908362],\n",
            "        [ 1.761308  ]]], dtype=float32)\n",
            "h_         = tensor([[[0.0000],\n",
            "         [0.4175],\n",
            "         [1.0457],\n",
            "         [0.0000],\n",
            "         [0.1712],\n",
            "         [2.9629],\n",
            "    ...      [2.0377],\n",
            "         [0.7515],\n",
            "         [0.1187],\n",
            "         [3.2562],\n",
            "         [1.2817]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a39570db790>\n",
            "model_     = RNN(11, 1)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[0.0000000e+00]\n",
            "  [0.0000000e+00]\n",
            "  [0.0000000e+00]\n",
            "  [0.0000000e+00]\n",
            "  [0.0000000e+00]\n",
            "  [2.5662563e+...000e+00]\n",
            "  [2.3002307e+00]\n",
            "  [1.9830031e+00]\n",
            "  [0.0000000e+00]\n",
            "  [0.0000000e+00]\n",
            "  [2.3311479e+00]\n",
            "  [1.2269504e+00]]])\n",
            "output_    = tensor([[[0.0000],\n",
            "         [0.0000],\n",
            "         [0.5735],\n",
            "         [0.0000],\n",
            "         [0.4855],\n",
            "         [3.4913],\n",
            "    ...      [2.0377],\n",
            "         [0.7515],\n",
            "         [0.1187],\n",
            "         [3.2562],\n",
            "         [1.2817]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[-0.7910305 , -1.4552466 , -0.6010427 , ..., -2.2761812 ,\n",
            "         -1.201621  ,  1.8649968 ],\n",
            "        [-0.4447...\n",
            "        [-0.7490011 , -0.07511813, -0.36062554, ..., -0.15201077,\n",
            "          1.8725417 ,  0.43609267]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956cc40d0>, array([[[0.        ],\n",
            "        [0.41752112],\n",
            "        [1...[1.9830031 ],\n",
            "        [0.        ],\n",
            "        [0.        ],\n",
            "        [2.331148  ],\n",
            "        [1.2269504 ]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 11 / 15 (73.3%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 0.92500603\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 7.6657853\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.      ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.417521],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [1.045673],...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.      ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.      ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.120667],...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956cc40d0>, array([[[0.        ],\n",
            "        [0.41752112],\n",
            "        [1...[1.9830031 ],\n",
            "        [0.        ],\n",
            "        [0.        ],\n",
            "        [2.331148  ],\n",
            "        [1.2269504 ]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m____________________________ test_rnn[cuda-relu-False-True-1-11-15-2-1] ____________________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 2, batch_size = 15, input_size = 11, hidden_size = 1, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.93770057]\n",
            "  [2.2719119 ]\n",
            "  [2.8917413 ]\n",
            "  [0.        ]\n",
            "  [1.5612354 ]\n",
            "  [3.461988  ]\n",
            "  [3.6974745 ]...0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]])\n",
            "h0         = array([[[-0.08978657],\n",
            "        [ 0.45799196],\n",
            "        [-1.4858687 ],\n",
            "        [-0.50766563],\n",
            "        [ 0.5563185 ],\n",
            "   ...2813827 ],\n",
            "        [-1.0128185 ],\n",
            "        [-0.88051647],\n",
            "        [-1.2160983 ],\n",
            "        [-1.8740114 ]]], dtype=float32)\n",
            "h_         = tensor([[[0.0000],\n",
            "         [0.8272],\n",
            "         [1.4470],\n",
            "         [0.0000],\n",
            "         [0.1165],\n",
            "         [2.0172],\n",
            "    ...      [0.0000],\n",
            "         [0.0410],\n",
            "         [0.0410],\n",
            "         [0.0126],\n",
            "         [0.0410]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a3956bdcfd0>\n",
            "model_     = RNN(11, 1, num_layers=2)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]])\n",
            "output_    = tensor([[[0.0410],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [0.0410],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "    ...      [0.0000],\n",
            "         [0.0410],\n",
            "         [0.0410],\n",
            "         [0.0126],\n",
            "         [0.0410]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[-2.314014  ,  0.926872  , -0.22506419, -1.1011095 ,\n",
            "          1.6149513 , -1.2449363 , -0.6702216 , -0.916026...   1.4987481 ,  1.0702145 , -0.6019876 ,  0.59308046,\n",
            "         -0.04079366,  0.8609623 , -0.37970525]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956cc7880>, array([[[0.        ],\n",
            "        [0.8271698 ],\n",
            "        [1...[0.        ],\n",
            "        [0.        ],\n",
            "        [0.        ],\n",
            "        [0.        ],\n",
            "        [0.        ]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 20 / 30 (66.7%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 1.4447422\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 1.\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.      ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.82717 ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [1.446999],...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.937701],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [2.271912],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [2.891741],...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956cc7880>, array([[[0.        ],\n",
            "        [0.8271698 ],\n",
            "        [1...[0.        ],\n",
            "        [0.        ],\n",
            "        [0.        ],\n",
            "        [0.        ],\n",
            "        [0.        ]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m___________________________ test_rnn[cuda-relu-False-True-1-11-15-2-13] ____________________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 2, batch_size = 15, input_size = 11, hidden_size = 1, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [1.6703073 ]\n",
            "  [0.        ]...0.71337605]\n",
            "  [0.5003642 ]\n",
            "  [0.45984638]\n",
            "  [1.0275211 ]\n",
            "  [0.        ]\n",
            "  [0.22442657]\n",
            "  [1.2499963 ]\n",
            "  [0.71337605]]])\n",
            "h0         = array([[[ 1.0559453 ],\n",
            "        [ 0.5076337 ],\n",
            "        [ 1.9702148 ],\n",
            "        [-1.2256718 ],\n",
            "        [ 1.3649867 ],\n",
            "   ...76216406],\n",
            "        [ 0.10330244],\n",
            "        [-1.8892632 ],\n",
            "        [-0.183853  ],\n",
            "        [-0.11640355]]], dtype=float32)\n",
            "h_         = tensor([[[0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [2.6357],\n",
            "    ...      [0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [0.6786],\n",
            "         [0.0000]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 1\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a3977a82020>\n",
            "model_     = RNN(11, 1, num_layers=2)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[1.2103333 ]\n",
            "  [1.2103333 ]\n",
            "  [1.2103333 ]\n",
            "  [1.6521714 ]\n",
            "  [1.2103333 ]\n",
            "  [1.2103333 ]\n",
            "  [2.6307523 ]...0.71337605]\n",
            "  [0.5003642 ]\n",
            "  [0.45984638]\n",
            "  [1.0275211 ]\n",
            "  [0.        ]\n",
            "  [0.22442657]\n",
            "  [1.2499963 ]\n",
            "  [0.71337605]]])\n",
            "output_    = tensor([[[0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [0.8980],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "    ...      [0.0000],\n",
            "         [0.0000],\n",
            "         [0.0000],\n",
            "         [0.6786],\n",
            "         [0.0000]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[ 0.27998576, -0.31334552, -0.14212188, ..., -1.1984026 ,\n",
            "          1.0583023 ,  0.1483405 ],\n",
            "        [ 1.3604...\n",
            "        [ 0.43645406, -0.05988122, -1.0637692 , ...,  0.7258711 ,\n",
            "          0.34199414,  0.71277946]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956b74280>, array([[[0.        ],\n",
            "        [0.        ],\n",
            "        [0...[1.0275211 ],\n",
            "        [0.        ],\n",
            "        [0.22442657],\n",
            "        [1.2499963 ],\n",
            "        [0.71337605]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 17 / 30 (56.7%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 1.3664356\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 25.451506\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.      ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.      ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.      ],...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.      ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.      ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.      ],...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956b74280>, array([[[0.        ],\n",
            "        [0.        ],\n",
            "        [0...[1.0275211 ],\n",
            "        [0.        ],\n",
            "        [0.22442657],\n",
            "        [1.2499963 ],\n",
            "        [0.71337605]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m____________________________ test_rnn[cuda-relu-False-True-12-1-1-1-1] _____________________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 1, batch_size = 1, input_size = 1, hidden_size = 12, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.34601295 0.         0.         0.47542608 0.         0.\n",
            "   0.         0.32273483 0.         0.46578535 0.         0.        ]]])\n",
            "h0         = array([[[ 0.66762257, -0.0407002 ,  1.0441549 ,  0.44878227,\n",
            "          1.6919594 ,  1.4774001 ,  0.34843904, -0.45060644,\n",
            "          0.09969667,  0.56632006,  1.4943632 ,  0.831512  ]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[0.5142, 0.0000, 0.0000, 0.0000, 0.3957, 0.3498, 0.0000, 0.0000,\n",
            "          0.1202, 0.0000, 0.0000, 0.3045]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a3956d279d0>\n",
            "model_     = RNN(1, 12)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[0.34601295 0.         0.         0.47542608 0.         0.\n",
            "   0.         0.32273483 0.         0.46578535 0.         0.        ]]])\n",
            "output_    = tensor([[[0.5142, 0.0000, 0.0000, 0.0000, 0.3957, 0.3498, 0.0000, 0.0000,\n",
            "          0.1202, 0.0000, 0.0000, 0.3045]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[0.5235594]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956cc7e20>, array([[[0.5142149 , 0.        , 0.        , 0.       ...        0.        , 0.        , 0.32273483, 0.        , 0.46578535,\n",
            "         0.        , 0.        ]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 8 / 12 (66.7%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 0.47542608\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 1.\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.514215, 0.      , 0.      , 0.      , 0.395682, 0.349835,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.      , 0.      , 0.120211, 0.      , 0.      , 0.304491]]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                 dtype=float32)\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.346013, 0.      , 0.      , 0.475426, 0.      , 0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.      , 0.322735, 0.      , 0.465785, 0.      , 0.      ]]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                 dtype=float32)\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956cc7e20>, array([[[0.5142149 , 0.        , 0.        , 0.       ...        0.        , 0.        , 0.32273483, 0.        , 0.46578535,\n",
            "         0.        , 0.        ]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m____________________________ test_rnn[cuda-relu-False-True-12-1-1-1-13] ____________________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 1, batch_size = 1, input_size = 1, hidden_size = 12, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.         0.         0.1898514  0.21028075 0.         0.\n",
            "   0.         0.         0.20033526 0.         0.02860532 0.00359609]]])\n",
            "h0         = array([[[-0.6185052 ,  0.51892537, -0.9932844 ,  0.7814067 ,\n",
            "          0.23083605, -0.00810497,  0.55297154, -0.36887202,\n",
            "         -0.22348207, -0.92135394,  2.015648  , -0.32119972]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[0.0000, 0.0000, 0.2973, 0.0282, 0.1074, 0.0000, 0.4114, 0.4897,\n",
            "          0.0000, 0.0000, 0.0369, 0.5683]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a3977756800>\n",
            "model_     = RNN(1, 12)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[0.         0.         0.23823926 0.3707453  0.         0.\n",
            "   0.         0.         0.26974624 0.     ...0.         0.1898514  0.21028075 0.         0.\n",
            "   0.         0.         0.20033526 0.         0.02860532 0.00359609]]])\n",
            "output_    = tensor([[[0.0000, 0.0000, 0.2628, 0.2224, 0.0000, 0.0000, 0.4886, 0.3113,\n",
            "          0.0000, 0.0000, 0.1048, 0.3161]],\n",
            "... 0.2973, 0.0282, 0.1074, 0.0000, 0.4114, 0.4897,\n",
            "          0.0000, 0.0000, 0.0369, 0.5683]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[-0.45162433]],\n",
            "\n",
            "       [[ 0.9409663 ]],\n",
            "\n",
            "       [[-0.09365293]],\n",
            "\n",
            "       [[ 0.29577273]],\n",
            "\n",
            "       [[ 0.337349...]],\n",
            "\n",
            "       [[ 1.2964863 ]],\n",
            "\n",
            "       [[ 0.13808292]],\n",
            "\n",
            "       [[-0.22564246]],\n",
            "\n",
            "       [[-0.11701173]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a395712e5f0>, array([[[0.        , 0.        , 0.29725775, 0.0282072...        0.        , 0.        , 0.        , 0.20033526, 0.        ,\n",
            "         0.02860532, 0.00359609]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 8 / 12 (66.7%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 0.5647204\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 157.03734\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.      , 0.      , 0.297258, 0.028207, 0.107439, 0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.411418, 0.489667, 0.      , 0.      , 0.036879, 0.568316]]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                 dtype=float32)\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.      , 0.      , 0.189851, 0.210281, 0.      , 0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.      , 0.      , 0.200335, 0.      , 0.028605, 0.003596]]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                 dtype=float32)\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a395712e5f0>, array([[[0.        , 0.        , 0.29725775, 0.0282072...        0.        , 0.        , 0.        , 0.20033526, 0.        ,\n",
            "         0.02860532, 0.00359609]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m____________________________ test_rnn[cuda-relu-False-True-12-1-1-2-1] _____________________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 2, batch_size = 1, input_size = 1, hidden_size = 12, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.         0.         0.         0.2957462  0.         0.\n",
            "   0.         0.44180238 0.03533789 0.14261...0.10146378 0.31505793 0.         0.38178375 0.\n",
            "   0.         0.         0.4488774  0.         0.         0.19671504]]])\n",
            "h0         = array([[[-1.004145  , -0.11885492, -0.33534074, -0.14288065,\n",
            "         -0.64296883, -1.0908973 ,  2.030668  ,  0.489197...597021 , -0.10439435, -0.6761051 ,\n",
            "          0.5101348 ,  0.03279088, -0.79833263, -2.9198458 ]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[0.4815, 0.1136, 0.0403, 0.0000, 0.2313, 0.1359, 0.5548, 0.0000,\n",
            "          0.0943, 0.1049, 0.0000, 0.0425]],\n",
            "... 0.0380, 0.2218, 0.1972, 0.5073, 0.2705, 0.5636,\n",
            "          0.0000, 0.1660, 0.1716, 0.2649]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a3957156950>\n",
            "model_     = RNN(1, 12, num_layers=2)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[0.         0.10146378 0.31505793 0.         0.38178375 0.\n",
            "   0.         0.         0.4488774  0.         0.         0.19671504]]])\n",
            "output_    = tensor([[[0.3672, 0.0851, 0.0380, 0.2218, 0.1972, 0.5073, 0.2705, 0.5636,\n",
            "          0.0000, 0.1660, 0.1716, 0.2649]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[-0.507352]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956e24700>, array([[[0.48152184, 0.11358508, 0.04030568, 0.       ...        0.        , 0.        , 0.        , 0.4488774 , 0.        ,\n",
            "         0.        , 0.19671504]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 24 / 24 (100%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 0.56364745\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 1.6676803\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.481522, 0.113585, 0.040306, 0.      , 0.231263, 0.135948,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.554812, 0.      , 0.09427 , 0.104882, 0.      , 0.042543]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE           ...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.      , 0.      , 0.      , 0.295746, 0.      , 0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.      , 0.441802, 0.035338, 0.142614, 0.508586, 0.556286]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE           ...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956e24700>, array([[[0.48152184, 0.11358508, 0.04030568, 0.       ...        0.        , 0.        , 0.        , 0.4488774 , 0.        ,\n",
            "         0.        , 0.19671504]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m____________________________ test_rnn[cuda-relu-False-True-12-1-1-2-13] ____________________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 2, batch_size = 1, input_size = 1, hidden_size = 12, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.06272033 0.1941027  0.07977164 0.6487266  0.37275535 0.\n",
            "   0.         0.         0.         0.89055...0.         0.         0.         0.         0.\n",
            "   0.04633008 0.70840085 0.         0.         0.         0.10295346]]])\n",
            "h0         = array([[[ 0.24131125,  1.121871  , -0.16435657,  0.568722  ,\n",
            "         -0.7647614 ,  1.5320107 , -0.9737367 ,  1.127725...2785014, -1.5902991 ,  0.2828532 ,\n",
            "          1.050924  , -1.4927189 ,  0.6889042 , -1.7933518 ]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[0.0472, 0.1036, 0.5816, 0.0000, 0.3383, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.4246, 0.0000, 0.1189]],\n",
            "... 0.5399, 0.1999, 0.1874, 0.0000, 0.4297, 0.3363,\n",
            "          0.0000, 0.2726, 0.0000, 0.1618]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a39570da200>\n",
            "model_     = RNN(1, 12, num_layers=2)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[0.54685557 0.         0.         0.         0.         0.\n",
            "   0.         0.6545123  0.         0.     ...0.         0.         0.         0.         0.\n",
            "   0.04633008 0.70840085 0.         0.         0.         0.10295346]]])\n",
            "output_    = tensor([[[0.3367, 0.0000, 0.4787, 0.1614, 0.3457, 0.0000, 0.1283, 0.3153,\n",
            "          0.0000, 0.2142, 0.0000, 0.0378]],\n",
            "... 0.5399, 0.1999, 0.1874, 0.0000, 0.4297, 0.3363,\n",
            "          0.0000, 0.2726, 0.0000, 0.1618]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[-1.7325613 ]],\n",
            "\n",
            "       [[ 0.7279965 ]],\n",
            "\n",
            "       [[-0.62691915]],\n",
            "\n",
            "       [[-1.3557853 ]],\n",
            "\n",
            "       [[-0.932760...]],\n",
            "\n",
            "       [[ 0.09337981]],\n",
            "\n",
            "       [[-1.345365  ]],\n",
            "\n",
            "       [[ 1.9569808 ]],\n",
            "\n",
            "       [[-1.1225699 ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956b75cf0>, array([[[0.04715052, 0.10363671, 0.5816426 , 0.       ...        0.        , 0.04633008, 0.70840085, 0.        , 0.        ,\n",
            "         0.        , 0.10295346]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 17 / 24 (70.8%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 0.6487266\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 8.274313\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.047151, 0.103637, 0.581643, 0.      , 0.338341, 0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.      , 0.      , 0.      , 0.424633, 0.      , 0.11886 ]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE           ...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.06272 , 0.194103, 0.079772, 0.648727, 0.372755, 0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.      , 0.      , 0.      , 0.890553, 0.199842, 0.      ]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE           ...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956b75cf0>, array([[[0.04715052, 0.10363671, 0.5816426 , 0.       ...        0.        , 0.04633008, 0.70840085, 0.        , 0.        ,\n",
            "         0.        , 0.10295346]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m____________________________ test_rnn[cuda-relu-False-True-12-1-15-1-1] ____________________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 1, batch_size = 15, input_size = 1, hidden_size = 12, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.3129388  0.00402682 0.13174345 0.         0.08709898 0.\n",
            "   0.48152778 0.         0.         0.32739...0.03276869 0.12519151 0.         0.20970175 0.\n",
            "   0.32780552 0.         0.         0.15611309 0.         0.        ]]])\n",
            "h0         = array([[[-1.4798547 , -0.9015725 ,  2.5526283 , -0.9799308 ,\n",
            "          0.20963514, -1.4043618 , -0.09302479, -0.386756...186824 , -0.08814752, -1.4654843 ,\n",
            "          0.4585919 , -1.3164103 , -0.25259322,  1.0699219 ]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[0.3827, 0.1192, 0.0000, 0.2369, 0.0000, 0.0736, 0.0000, 0.0000,\n",
            "          0.4857, 0.0373, 0.1294, 0.3662],\n",
            " ... 0.0000, 0.3100, 0.0000, 0.0584, 0.0000, 0.0000,\n",
            "          0.2915, 0.0000, 0.0000, 0.4254]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a395730d210>\n",
            "model_     = RNN(1, 12)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[0.3129388  0.00402682 0.13174345 0.         0.08709898 0.\n",
            "   0.48152778 0.         0.         0.32739...0.03276869 0.12519151 0.         0.20970175 0.\n",
            "   0.32780552 0.         0.         0.15611309 0.         0.        ]]])\n",
            "output_    = tensor([[[0.3827, 0.1192, 0.0000, 0.2369, 0.0000, 0.0736, 0.0000, 0.0000,\n",
            "          0.4857, 0.0373, 0.1294, 0.3662],\n",
            " ... 0.0000, 0.3100, 0.0000, 0.0584, 0.0000, 0.0000,\n",
            "          0.2915, 0.0000, 0.0000, 0.4254]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[-0.830789  ],\n",
            "        [-1.5738721 ],\n",
            "        [-0.81522024],\n",
            "        [ 0.9200792 ],\n",
            "        [ 0.61454463],\n",
            "   ...462892  ],\n",
            "        [ 0.8337903 ],\n",
            "        [ 1.1568013 ],\n",
            "        [-0.4374638 ],\n",
            "        [ 0.08471887]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956b76830>, array([[[0.3827285 , 0.1191875 , 0.        , 0.2368561...        0.        , 0.32780552, 0.        , 0.        , 0.15611309,\n",
            "         0.        , 0.        ]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 148 / 180 (82.2%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 0.6062983\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 28.598385\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.382728, 0.119188, 0.      , 0.236856, 0.      , 0.07358 ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.      , 0.      , 0.485691, 0.037272, 0.129435, 0.366196],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.437884, 0.095859, 0.      , 0.177489, 0.      , 0.085863,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.312939, 0.004027, 0.131743, 0.      , 0.087099, 0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.481528, 0.      , 0.      , 0.327394, 0.      , 0.      ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.368094, 0.      , 0.137061, 0.      , 0.      , 0.      ,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956b76830>, array([[[0.3827285 , 0.1191875 , 0.        , 0.2368561...        0.        , 0.32780552, 0.        , 0.        , 0.15611309,\n",
            "         0.        , 0.        ]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m___________________________ test_rnn[cuda-relu-False-True-12-1-15-1-13] ____________________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 1, batch_size = 15, input_size = 1, hidden_size = 12, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.         0.         0.5534678  0.         0.         0.7158984\n",
            "   0.         0.         0.23397295 ...   0.55508566 0.         0.         0.61706144\n",
            "   0.         0.         0.186406   0.5207325  0.         0.        ]]])\n",
            "h0         = array([[[ 0.7889376 , -0.74948597,  0.3381314 , -1.0598115 ,\n",
            "         -0.05822528, -0.8679909 ,  1.1359406 , -0.821512...5456305,  0.5694219 , -0.90761775,\n",
            "          0.3813511 ,  0.23065251, -0.88299483, -0.580006  ]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[0.0000, 0.8955, 0.0000, 0.0000, 0.1060, 0.7622, 0.0000, 0.0000,\n",
            "          0.0000, 0.3946, 0.0720, 0.1581],\n",
            " ... 0.0000, 0.0000, 0.0000, 0.6531, 0.0000, 0.0000,\n",
            "          0.0000, 0.3407, 0.0486, 0.0381]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a397772d720>\n",
            "model_     = RNN(1, 12)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[0.         0.         0.4924894  ... 0.39962053 0.         0.09220016]\n",
            "  [0.00754585 0.         0.486...1706 ... 0.46710613 0.         0.        ]\n",
            "  [0.         0.         0.55508566 ... 0.5207325  0.         0.        ]]])\n",
            "output_    = tensor([[[0.0000, 0.7153, 0.0000,  ..., 0.3978, 0.2652, 0.2221],\n",
            "         [0.0000, 0.4645, 0.0000,  ..., 0.2065, 0.136...7, 0.0000, 0.0000],\n",
            "         [0.0000, 0.8286, 0.0000,  ..., 0.3407, 0.0486, 0.0381]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[ 1.4484506 ],\n",
            "        [-0.22625712],\n",
            "        [-1.0340168 ],\n",
            "        [ 0.49442416],\n",
            "        [-1.3419626 ],\n",
            "   ...61392176],\n",
            "        [-0.76019394],\n",
            "        [ 0.20403434],\n",
            "        [-0.08619408],\n",
            "        [ 0.7077755 ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956b768c0>, array([[[0.        , 0.8955155 , 0.        , 0.       ...        0.61706144, 0.        , 0.        , 0.186406  , 0.5207325 ,\n",
            "         0.        , 0.        ]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 102 / 180 (56.7%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 1.0116673\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 107.57261\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.      , 0.895516, 0.      , 0.      , 0.106041, 0.762226,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.      , 0.      , 0.      , 0.394626, 0.072031, 0.158079],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.      , 0.632854, 0.      , 0.      , 0.      , 0.373047,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.      , 0.      , 0.553468, 0.      , 0.      , 0.715898,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.      , 0.      , 0.233973, 0.567775, 0.      , 0.030817],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.035547, 0.      , 0.518115, 0.      , 0.      , 0.31578 ,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956b768c0>, array([[[0.        , 0.8955155 , 0.        , 0.       ...        0.61706144, 0.        , 0.        , 0.186406  , 0.5207325 ,\n",
            "         0.        , 0.        ]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m____________________________ test_rnn[cuda-relu-False-True-12-1-15-2-1] ____________________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 2, batch_size = 15, input_size = 1, hidden_size = 12, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.14399749 0.         0.40075278 0.         0.         0.\n",
            "   0.36473563 0.         0.         0.70819...0.         0.         0.         0.716114   0.\n",
            "   0.         0.         0.16313104 0.49023438 0.268678   0.47074026]]])\n",
            "h0         = array([[[-2.1016486 ,  1.2422073 , -0.4641842 , -0.3832563 ,\n",
            "         -0.11853369, -0.71403205,  1.0592198 ,  0.559932...7012507, -2.1669168 , -0.5027071 ,\n",
            "         -0.5422562 ,  1.2613298 , -0.74452716, -0.47802162]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[0.7585, 0.0000, 0.0000, 0.1568, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.5168, 0.0000, 0.4944],\n",
            " ... 0.0000, 0.0000, 0.0303, 0.0000, 0.0000, 0.0000,\n",
            "          0.0287, 0.0000, 0.0000, 0.0000]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a3956fd34c0>\n",
            "model_     = RNN(1, 12, num_layers=2)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[0.         0.         0.         0.         0.6791225  0.\n",
            "   0.         0.         0.02740605 0.51643...0.         0.         0.         0.716114   0.\n",
            "   0.         0.         0.16313104 0.49023438 0.268678   0.47074026]]])\n",
            "output_    = tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.1650, 0.0000, 0.0000, 0.2489,\n",
            "          0.0000, 0.0376, 0.0000, 0.0000],\n",
            " ... 0.0000, 0.0000, 0.0303, 0.0000, 0.0000, 0.0000,\n",
            "          0.0287, 0.0000, 0.0000, 0.0000]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[ 2.6265104 ],\n",
            "        [-0.6170632 ],\n",
            "        [ 0.9179036 ],\n",
            "        [ 0.10391255],\n",
            "        [ 1.0894146 ],\n",
            "   ...41123387],\n",
            "        [ 1.4987602 ],\n",
            "        [-0.53929085],\n",
            "        [ 0.61204445],\n",
            "        [ 0.02817509]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956b77520>, array([[[0.7585151 , 0.        , 0.        , 0.1567816...        0.        , 0.        , 0.        , 0.16313104, 0.49023438,\n",
            "         0.268678  , 0.47074026]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 216 / 360 (60%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 0.70307523\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 4.267558\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.758515, 0.      , 0.      , 0.156782, 0.      , 0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.      , 0.      , 0.      , 0.516771, 0.      , 0.49436 ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.      , 0.227189, 0.      , 0.019858, 0.265793, 0.      ,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.143997, 0.      , 0.400753, 0.      , 0.      , 0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.364736, 0.      , 0.      , 0.70819 , 0.101965, 0.718133],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.      , 0.      , 0.530066, 0.      , 0.311791, 0.      ,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956b77520>, array([[[0.7585151 , 0.        , 0.        , 0.1567816...        0.        , 0.        , 0.        , 0.16313104, 0.49023438,\n",
            "         0.268678  , 0.47074026]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m___________________________ test_rnn[cuda-relu-False-True-12-1-15-2-13] ____________________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 2, batch_size = 15, input_size = 1, hidden_size = 12, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[5.21022826e-03 1.98590875e-01 2.27289021e-01 0.00000000e+00\n",
            "   0.00000000e+00 3.49997938e-01 3.879998...000e+00 0.00000000e+00 0.00000000e+00 3.07573944e-01\n",
            "   2.25140929e-01 0.00000000e+00 2.04763770e-01 0.00000000e+00]]])\n",
            "h0         = array([[[ 7.26349950e-01, -9.68443155e-01, -1.10421097e+00,\n",
            "          2.19915509e-02, -1.59169066e+00, -1.07028830e+00..., -1.06943727e+00, -1.51787448e+00,\n",
            "          1.55751675e-01,  1.35575902e+00,  1.57582447e-01]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2158, 0.0000,\n",
            "          0.0000, 0.5713, 0.1544, 0.1292],\n",
            " ... 0.3409, 0.0000, 0.0000, 0.0000, 0.1372, 0.2395,\n",
            "          0.0000, 0.0000, 0.0000, 0.0833]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 1\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a3956e5ae60>\n",
            "model_     = RNN(1, 12, num_layers=2)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[0.01232462 0.3472673  0.         ... 0.         0.1418316  0.        ]\n",
            "  [0.         0.32033777 0.   ...     ... 0.         0.10285967 0.        ]\n",
            "  [0.         0.35136688 0.         ... 0.         0.20476377 0.        ]]])\n",
            "output_    = tensor([[[0.2146, 0.0581, 0.2013,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.2010, 0.0765, 0.1813,  ..., 0.0000, 0.000...0, 0.0000, 0.1083],\n",
            "         [0.0261, 0.1802, 0.3409,  ..., 0.0000, 0.0000, 0.0833]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[-0.86852336],\n",
            "        [-0.41917482],\n",
            "        [ 0.70354635],\n",
            "        [-0.01970863],\n",
            "        [-0.7823463 ],\n",
            "   ...2100415 ],\n",
            "        [ 0.5473822 ],\n",
            "        [ 0.4887096 ],\n",
            "        [-0.6151639 ],\n",
            "        [-1.1731654 ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956c280d0>, array([[[0.        , 0.        , 0.        , 0.       ...e+00, 3.07573944e-01,\n",
            "         2.25140929e-01, 0.00000000e+00, 2.04763770e-01, 0.00000000e+00]]],\n",
            "      dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 243 / 360 (67.5%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 0.5432429\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 58.594\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.215768, 0.      , 0.      , 0.571291, 0.154353, 0.1292  ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[5.210228e-03, 1.985909e-01, 2.272890e-01, 0.000000e+00,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.000000e+00, 3.499979e-01, 3.879999e-01, 0.000000e+00,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    9.236068e-02, 5.147969e-01, 2.470649e-01, 5.902245e-01],...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956c280d0>, array([[[0.        , 0.        , 0.        , 0.       ...e+00, 3.07573944e-01,\n",
            "         2.25140929e-01, 0.00000000e+00, 2.04763770e-01, 0.00000000e+00]]],\n",
            "      dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m____________________________ test_rnn[cuda-relu-False-True-12-11-1-1-1] ____________________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 1, batch_size = 1, input_size = 11, hidden_size = 12, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.         0.         0.4161367  0.4615733  0.8803284  0.8823261\n",
            "   1.0653148  0.41284817 0.         0.         0.         0.32040903]]])\n",
            "h0         = array([[[-0.40735278,  0.70488966,  0.5857383 , -1.4241087 ,\n",
            "         -0.1380252 ,  0.47251284, -1.4674047 ,  0.6356569 ,\n",
            "         -0.77591926, -1.2730281 ,  1.4885229 , -0.82872194]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[0.0000, 0.0000, 0.0000, 0.5941, 0.2391, 0.4813, 0.6498, 0.4437,\n",
            "          0.2798, 0.3298, 0.0000, 0.0000]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a3956c0b730>\n",
            "model_     = RNN(11, 12)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[0.         0.         0.4161367  0.4615733  0.8803284  0.8823261\n",
            "   1.0653148  0.41284817 0.         0.         0.         0.32040903]]])\n",
            "output_    = tensor([[[0.0000, 0.0000, 0.0000, 0.5941, 0.2391, 0.4813, 0.6498, 0.4437,\n",
            "          0.2798, 0.3298, 0.0000, 0.0000]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[ 0.7862132 ,  0.6036022 ,  0.26550174,  0.7102276 ,\n",
            "         -1.3960762 ,  1.0111002 , -0.09472585, -1.0282967 ,\n",
            "         -0.39164144,  0.1943645 , -0.28276187]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956e24700>, array([[[0.        , 0.        , 0.        , 0.5941053...        0.8823261 , 1.0653148 , 0.41284817, 0.        , 0.        ,\n",
            "         0.        , 0.32040903]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 9 / 12 (75%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 0.6411946\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 1.\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.      , 0.      , 0.      , 0.594105, 0.239134, 0.481345,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.649752, 0.443741, 0.279795, 0.329806, 0.      , 0.      ]]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                 dtype=float32)\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.      , 0.      , 0.416137, 0.461573, 0.880328, 0.882326,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    1.065315, 0.412848, 0.      , 0.      , 0.      , 0.320409]]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                 dtype=float32)\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956e24700>, array([[[0.        , 0.        , 0.        , 0.5941053...        0.8823261 , 1.0653148 , 0.41284817, 0.        , 0.        ,\n",
            "         0.        , 0.32040903]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m___________________________ test_rnn[cuda-relu-False-True-12-11-1-1-13] ____________________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 1, batch_size = 1, input_size = 11, hidden_size = 12, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.         0.         0.         0.         0.41798592 0.6479728\n",
            "   0.7050439  0.         0.         0.         0.57461995 0.        ]]])\n",
            "h0         = array([[[ 0.7316706 ,  0.02501871, -0.23642695, -0.9563672 ,\n",
            "          0.7090555 ,  0.5739972 , -1.7297186 , -2.0077114 ,\n",
            "          0.75884306,  0.61930454, -0.65352815, -1.8441725 ]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[0.0017, 0.0000, 0.0000, 0.0000, 0.2905, 0.1567, 1.2176, 0.0000,\n",
            "          0.0000, 0.0000, 0.3518, 0.0000]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a3977482bc0>\n",
            "model_     = RNN(11, 12)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[0.00000000e+00 0.00000000e+00 1.57558513e+00 0.00000000e+00\n",
            "   0.00000000e+00 1.13254559e+00 0.000000...916e-01 6.47972822e-01 7.05043912e-01 0.00000000e+00\n",
            "   0.00000000e+00 0.00000000e+00 5.74619949e-01 0.00000000e+00]]])\n",
            "output_    = tensor([[[0.0000e+00, 0.0000e+00, 9.5203e-01, 0.0000e+00, 1.7344e-01,\n",
            "          6.9011e-01, 0.0000e+00, 0.0000e+00, 8....668e-01, 1.2176e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "          3.5183e-01, 0.0000e+00]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[-4.48798388e-01,  4.98125136e-01, -1.96646914e-01,\n",
            "          6.71568811e-01, -1.47339582e+00, -1.80850947e+00...         6.67635322e-01,  1.71365127e-01, -1.00058925e+00,\n",
            "          1.21392202e+00,  1.55785632e+00]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956cc76d0>, array([[[0.0016592 , 0.        , 0.        , 0.       ...        0.6479728 , 0.7050439 , 0.        , 0.        , 0.        ,\n",
            "         0.57461995, 0.        ]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 5 / 12 (41.7%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 0.5125526\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 0.75819963\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.001659, 0.      , 0.      , 0.      , 0.290458, 0.15668 ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    1.217597, 0.      , 0.      , 0.      , 0.35183 , 0.      ]]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                 dtype=float32)\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.      , 0.      , 0.      , 0.      , 0.417986, 0.647973,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.705044, 0.      , 0.      , 0.      , 0.57462 , 0.      ]]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                 dtype=float32)\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956cc76d0>, array([[[0.0016592 , 0.        , 0.        , 0.       ...        0.6479728 , 0.7050439 , 0.        , 0.        , 0.        ,\n",
            "         0.57461995, 0.        ]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m____________________________ test_rnn[cuda-relu-False-True-12-11-1-2-1] ____________________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 2, batch_size = 1, input_size = 11, hidden_size = 12, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.44796565 0.         0.         0.         0.6932323  0.\n",
            "   0.00191769 0.         0.         0.     ...   0.54800177 0.02195729 0.         0.03283132\n",
            "   0.         0.01290092 0.         0.         0.21517542 0.37730503]]])\n",
            "h0         = array([[[-0.8764219 , -0.96864283, -0.1227475 ,  0.8806006 ,\n",
            "          0.09962811,  0.13075903,  1.3503002 , -0.932053...608136 , -1.6050023 ,  0.9756196 ,\n",
            "         -0.9109524 , -2.0231183 ,  0.6213703 ,  0.48916048]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[0.2001, 0.0000, 0.1790, 0.0000, 0.9843, 0.0046, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000]],\n",
            "... 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2548,\n",
            "          0.0197, 0.0000, 0.5212, 0.0000]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a3956bd9e10>\n",
            "model_     = RNN(11, 12, num_layers=2)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[0.         0.540141   0.54800177 0.02195729 0.         0.03283132\n",
            "   0.         0.01290092 0.         0.         0.21517542 0.37730503]]])\n",
            "output_    = tensor([[[0.5312, 0.3312, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2548,\n",
            "          0.0197, 0.0000, 0.5212, 0.0000]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[-1.3663912 , -1.3129749 ,  1.0748427 , -0.91191375,\n",
            "          2.0462725 , -0.5199972 , -0.6249354 ,  0.2877402 ,\n",
            "         -1.2328838 , -1.7397748 ,  0.42670712]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956b77130>, array([[[0.20014428, 0.        , 0.17898081, 0.       ...        0.03283132, 0.        , 0.01290092, 0.        , 0.        ,\n",
            "         0.21517542, 0.37730503]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 14 / 24 (58.3%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 0.54800177\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 18.75294\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.200144, 0.      , 0.178981, 0.      , 0.984263, 0.004611,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.      , 0.      , 0.      , 0.      , 0.      , 0.      ]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE           ...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.447966, 0.      , 0.      , 0.      , 0.693232, 0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.001918, 0.      , 0.      , 0.      , 0.      , 0.      ]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE           ...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956b77130>, array([[[0.20014428, 0.        , 0.17898081, 0.       ...        0.03283132, 0.        , 0.01290092, 0.        , 0.        ,\n",
            "         0.21517542, 0.37730503]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m___________________________ test_rnn[cuda-relu-False-True-12-11-1-2-13] ____________________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 2, batch_size = 1, input_size = 11, hidden_size = 12, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 1\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.         0.6670363  0.         0.5029176  0.66666    0.\n",
            "   0.36858878 0.8994218  1.0485055  0.     ...0.         0.         0.20975529 0.         0.\n",
            "   0.13087761 0.         0.2442332  0.47829005 0.         0.        ]]])\n",
            "h0         = array([[[ 1.058002  ,  0.0115869 ,  0.6720075 ,  0.13448876,\n",
            "          0.47139353,  0.39308363, -2.0568125 , -0.481108...572414 , -0.80905014,  1.3166068 ,\n",
            "         -0.37876266, -1.0951818 , -0.17242531, -1.3780636 ]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[0.0272, 0.9892, 0.0000, 0.5296, 0.4655, 0.0000, 0.1924, 0.7249,\n",
            "          0.1998, 0.0000, 0.3954, 0.0000]],\n",
            "... 0.0000, 0.1629, 0.2723, 0.0675, 0.0062, 0.0000,\n",
            "          0.1438, 0.0205, 0.0000, 0.1177]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a3956e3e200>\n",
            "model_     = RNN(11, 12, num_layers=2)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[0.         0.         0.         0.         0.02761438 0.\n",
            "   0.37985006 0.         0.         0.62502...0.         0.         0.20975529 0.         0.\n",
            "   0.13087761 0.         0.2442332  0.47829005 0.         0.        ]]])\n",
            "output_    = tensor([[[0.0000, 0.4726, 0.0000, 0.0000, 0.5394, 0.0000, 0.4125, 0.0000,\n",
            "          0.0053, 0.0499, 0.0337, 0.0967]],\n",
            "... 0.0000, 0.1629, 0.2723, 0.0675, 0.0062, 0.0000,\n",
            "          0.1438, 0.0205, 0.0000, 0.1177]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[-1.0562003 , -0.12481209,  0.5284759 ,  2.3924866 ,\n",
            "         -0.24580707, -1.8438497 , -0.9249578 , -0.766937...   0.16108553, -1.8628938 ,  0.50843734,  0.21461909,\n",
            "          1.0800438 ,  0.40221888, -0.44034538]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956c284c0>, array([[[0.02718764, 0.9892019 , 0.        , 0.5296484...        0.        , 0.13087761, 0.        , 0.2442332 , 0.47829005,\n",
            "         0.        , 0.        ]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 16 / 24 (66.7%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 0.8486904\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 0.9570786\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.027188, 0.989202, 0.      , 0.529648, 0.465528, 0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.192426, 0.724932, 0.199815, 0.      , 0.395412, 0.      ]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE           ...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.      , 0.667036, 0.      , 0.502918, 0.66666 , 0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.368589, 0.899422, 1.048506, 0.      , 0.295936, 0.      ]],\u001b[0m\n",
            "\u001b[1m\u001b[31mE           ...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956c284c0>, array([[[0.02718764, 0.9892019 , 0.        , 0.5296484...        0.        , 0.13087761, 0.        , 0.2442332 , 0.47829005,\n",
            "         0.        , 0.        ]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m___________________________ test_rnn[cuda-relu-False-True-12-11-15-1-1] ____________________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 1, batch_size = 15, input_size = 11, hidden_size = 12, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.         1.2584621  0.         1.2334979  0.         0.9929764\n",
            "   0.         0.         0.         ...    0.         0.19973439 0.         0.2620921\n",
            "   0.7638237  0.04146266 0.         1.035955   0.01527983 0.19641998]]])\n",
            "h0         = array([[[-0.34688923,  0.12058017, -0.45824143, -0.9191538 ,\n",
            "         -0.7649141 ,  0.85422426, -0.15367262,  0.373051...319963 ,  0.49560773, -0.5043369 ,\n",
            "         -0.33064425, -0.61309534, -0.64337134,  0.2033129 ]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[0.0000, 1.2915, 0.0000, 0.6594, 0.0000, 0.8630, 0.0000, 0.0000,\n",
            "          0.0000, 0.5326, 0.3434, 0.2101],\n",
            " ... 0.0000, 0.0000, 0.0000, 0.1321, 0.4832, 0.0000,\n",
            "          0.0000, 0.7552, 0.0000, 0.0000]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a395706ff40>\n",
            "model_     = RNN(11, 12)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[0.         1.2584621  0.         1.2334979  0.         0.9929764\n",
            "   0.         0.         0.         ...    0.         0.19973439 0.         0.2620921\n",
            "   0.7638237  0.04146266 0.         1.035955   0.01527983 0.19641998]]])\n",
            "output_    = tensor([[[0.0000, 1.2915, 0.0000, 0.6594, 0.0000, 0.8630, 0.0000, 0.0000,\n",
            "          0.0000, 0.5326, 0.3434, 0.2101],\n",
            " ... 0.0000, 0.0000, 0.0000, 0.1321, 0.4832, 0.0000,\n",
            "          0.0000, 0.7552, 0.0000, 0.0000]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[-0.42692634,  0.23572864, -0.67035997,  1.9423443 ,\n",
            "          0.823731  ,  0.7739286 , -0.86794037,  1.423630...   0.65298826,  0.23557323,  0.36790264,  0.20956871,\n",
            "         -2.1090043 ,  0.5318383 , -0.51251096]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956c28af0>, array([[[0.        , 1.291508  , 0.        , 0.6594258...        0.2620921 , 0.7638237 , 0.04146266, 0.        , 1.035955  ,\n",
            "         0.01527983, 0.19641998]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 98 / 180 (54.4%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 0.57407224\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 2.9791424\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.      , 1.291508, 0.      , 0.659426, 0.      , 0.863017,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.      , 0.      , 0.      , 0.532607, 0.343445, 0.210105],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.101158, 0.547356, 0.      , 0.002072, 0.      , 0.423894,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.      , 1.258462, 0.      , 1.233498, 0.      , 0.992976,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.      , 0.      , 0.      , 0.813332, 0.69424 , 0.619402],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.025422, 0.51431 , 0.      , 0.576144, 0.      , 0.553853,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956c28af0>, array([[[0.        , 1.291508  , 0.        , 0.6594258...        0.2620921 , 0.7638237 , 0.04146266, 0.        , 1.035955  ,\n",
            "         0.01527983, 0.19641998]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m___________________________ test_rnn[cuda-relu-False-True-12-11-15-1-13] ___________________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 1, batch_size = 15, input_size = 11, hidden_size = 12, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.13122925 0.6690135  0.         0.         0.17632557 0.\n",
            "   0.3483087  0.05580094 0.01587003 0.11186...    0.         0.         0.35218573 0.4713553\n",
            "   0.27119654 0.8702564  0.0480254  0.48089254 0.2891602  0.        ]]])\n",
            "h0         = array([[[-0.32962915, -1.534836  , -0.00825986,  0.32061052,\n",
            "          0.10546742,  1.1556637 , -0.48237377, -1.080840...7992532, -1.0124444 , -0.8382948 ,\n",
            "         -1.0947556 ,  0.20077552, -0.9677219 , -1.1050828 ]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[0.0000, 0.3232, 0.0000, 0.0000, 0.3160, 0.0000, 0.7288, 0.0000,\n",
            "          0.0000, 0.1019, 0.0000, 0.0000],\n",
            " ... 0.0000, 0.1206, 0.3576, 0.0000, 0.5751, 0.6498,\n",
            "          0.0000, 0.5139, 0.0992, 0.0000]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 0\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a3956b804c0>\n",
            "model_     = RNN(11, 12)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 1\n",
            "output     = needle.Tensor([[[0.         0.05359036 0.         ... 0.         0.         0.48871902]\n",
            "  [0.9957632  0.         0.   ...     ... 0.75883037 0.         0.00754458]\n",
            "  [0.09503883 0.         0.         ... 0.48089254 0.2891602  0.        ]]])\n",
            "output_    = tensor([[[0.0000, 0.0000, 0.4455,  ..., 0.0000, 0.0000, 0.0590],\n",
            "         [0.7596, 0.0000, 0.2579,  ..., 0.8534, 0.000...2, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.5139, 0.0992, 0.0000]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[-0.1270844 ,  0.586107  , -0.9429692 , ...,  2.2089663 ,\n",
            "         -0.38387787,  1.4683505 ],\n",
            "        [ 0.2062...\n",
            "        [ 0.38401678, -0.36746952,  2.0066469 , ..., -1.2825098 ,\n",
            "          0.46490142,  0.3301008 ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956c295a0>, array([[[0.        , 0.32316998, 0.        , 0.       ...        0.4713553 , 0.27119654, 0.8702564 , 0.0480254 , 0.48089254,\n",
            "         0.2891602 , 0.        ]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 108 / 180 (60%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 0.7094768\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 6.1147757\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.      , 0.32317 , 0.      , 0.      , 0.316017, 0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.728793, 0.      , 0.      , 0.101931, 0.      , 0.      ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.476344, 0.001718, 0.220187, 0.      , 0.697923, 0.      ,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.131229, 0.669014, 0.      , 0.      , 0.176326, 0.      ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.348309, 0.055801, 0.01587 , 0.111866, 0.      , 0.      ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.609821, 0.33644 , 0.      , 0.      , 0.632286, 0.      ,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956c295a0>, array([[[0.        , 0.32316998, 0.        , 0.       ...        0.4713553 , 0.27119654, 0.8702564 , 0.0480254 , 0.48089254,\n",
            "         0.2891602 , 0.        ]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m___________________________ test_rnn[cuda-relu-False-True-12-11-15-2-1] ____________________________\u001b[0m\n",
            "\n",
            "seq_length = 1, num_layers = 2, batch_size = 15, input_size = 11, hidden_size = 12, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.         0.         0.         0.         0.37618372 0.7656022\n",
            "   0.         0.         0.         ...0.08381675 0.         0.9075966  0.         0.\n",
            "   0.         0.19765735 0.58628446 0.16358271 0.         0.        ]]])\n",
            "h0         = array([[[ 1.16870570e+00, -9.78562295e-01,  1.01036465e+00,\n",
            "          6.83633149e-01,  7.79867470e-01,  5.42766154e-01..., -2.45853916e-01,  6.74250364e-01,\n",
            "         -3.83896977e-02, -1.76038325e-01,  1.55713153e+00]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.3952, 0.6608, 0.0000, 0.0000,\n",
            "          0.0000, 0.3411, 0.0000, 0.0000],\n",
            " ... 0.0000, 0.2455, 0.0000, 0.0000, 0.0000, 0.3664,\n",
            "          0.2199, 0.2436, 0.0000, 0.0000]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a395730ddb0>\n",
            "model_     = RNN(11, 12, num_layers=2)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[0.         0.         0.         0.71997726 0.         0.19446465\n",
            "   0.14893886 0.         0.52581507...0.08381675 0.         0.9075966  0.         0.\n",
            "   0.         0.19765735 0.58628446 0.16358271 0.         0.        ]]])\n",
            "output_    = tensor([[[0.2626, 0.1958, 0.0000, 0.0067, 0.0000, 0.0000, 0.1231, 0.1029,\n",
            "          0.0591, 0.0000, 0.0000, 0.0000],\n",
            " ... 0.0000, 0.2455, 0.0000, 0.0000, 0.0000, 0.3664,\n",
            "          0.2199, 0.2436, 0.0000, 0.0000]]], grad_fn=<StackBackward0>)\n",
            "seq_length = 1\n",
            "x          = array([[[ 0.7993837 , -0.25389382,  0.7259235 ,  0.5463271 ,\n",
            "         -1.273866  ,  0.29827136, -0.6953715 , -0.274252...   1.0575736 ,  1.248338  , -0.926533  , -0.63948685,\n",
            "          0.68831325, -1.8373367 ,  0.4580096 ]]], dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956c29a20>, array([[[0.        , 0.        , 0.        , 0.       ...        0.        , 0.        , 0.19765735, 0.58628446, 0.16358271,\n",
            "         0.        , 0.        ]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 220 / 360 (61.1%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 0.86900014\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 9.750674\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.      , 0.      , 0.      , 0.      , 0.395179, 0.660849,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.      , 0.      , 0.      , 0.341124, 0.      , 0.      ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.111031, 0.      , 0.      , 1.777826, 0.612711, 0.216933,...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.      , 0.      , 0.      , 0.      , 0.376184, 0.765602,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.      , 0.      , 0.      , 0.773261, 0.      , 0.      ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.067272, 0.      , 0.      , 1.965289, 0.593717, 0.321687,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956c29a20>, array([[[0.        , 0.        , 0.        , 0.       ...        0.        , 0.        , 0.19765735, 0.58628446, 0.16358271,\n",
            "         0.        , 0.        ]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[31m\u001b[1m___________________________ test_rnn[cuda-relu-False-True-12-11-15-2-13] ___________________________\u001b[0m\n",
            "\n",
            "seq_length = 13, num_layers = 2, batch_size = 15, input_size = 11, hidden_size = 12, bias = True\n",
            "init_hidden = False, nonlinearity = 'relu', device = cuda()\n",
            "\n",
            "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mseq_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, SEQ_LENGTHS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_layers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NUM_LAYERS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BATCH_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INPUT_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mhidden_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, HIDDEN_SIZES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mbias\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, BIAS)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33minit_hidden\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, INIT_HIDDEN)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mnonlinearity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, NONLINEARITIES)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, _DEVICES, ids=[\u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_rnn\u001b[39;49;00m(seq_length, num_layers, batch_size, input_size, hidden_size, bias, init_hidden, nonlinearity, device):\u001b[90m\u001b[39;49;00m\n",
            "        x = np.random.randn(seq_length, batch_size, input_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "        h0 = np.random.randn(num_layers, batch_size, hidden_size).astype(np.float32)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model_ = torch.nn.RNN(input_size, hidden_size, num_layers=num_layers, bias=bias, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), torch.tensor(h0))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output_, h_ = model_(torch.tensor(x), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        model = nn.RNN(input_size, hidden_size, num_layers, bias, device=device, nonlinearity=nonlinearity)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mfor\u001b[39;49;00m k \u001b[95min\u001b[39;49;00m \u001b[96mrange\u001b[39;49;00m(num_layers):\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            model.rnn_cells[k].W_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mweight_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy().transpose(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m bias:\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_ih = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_ih_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "                model.rnn_cells[k].bias_hh = ndl.Tensor(\u001b[96mgetattr\u001b[39;49;00m(model_, \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mbias_hh_l\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mk\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).detach().numpy(), device=device)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m init_hidden:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), ndl.Tensor(h0, device=device))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            output, h = model(ndl.Tensor(x, device=device), \u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       np.testing.assert_allclose(h_.detach().numpy(), h.numpy(), atol=\u001b[94m1e-5\u001b[39;49;00m, rtol=\u001b[94m1e-5\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "batch_size = 15\n",
            "bias       = True\n",
            "device     = cuda()\n",
            "h          = needle.Tensor([[[0.         0.         0.25475803 0.         0.00209865 0.70213956\n",
            "   0.09098017 0.         0.        ...0.         0.         0.         0.14064243 0.\n",
            "   0.8353585  0.         0.00372666 0.         0.         0.        ]]])\n",
            "h0         = array([[[-0.70842975,  0.48682255,  0.25841329, -0.5178074 ,\n",
            "         -0.44200972, -0.6653528 ,  0.67937726,  1.176197...0986093,  0.42317468, -0.01993893,\n",
            "         -0.39027968, -3.1263225 , -0.933349  ,  0.63634855]]],\n",
            "      dtype=float32)\n",
            "h_         = tensor([[[0.0000e+00, 1.8360e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "          2.3019e-01, 1.4462e-01, 0.0000e+00, 0....072e-01, 2.6365e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "          0.0000e+00, 4.5113e-01]]], grad_fn=<StackBackward0>)\n",
            "hidden_size = 12\n",
            "init_hidden = False\n",
            "input_size = 11\n",
            "k          = 1\n",
            "model      = <needle.nn.nn_sequence.RNN object at 0x7a39775a4dc0>\n",
            "model_     = RNN(11, 12, num_layers=2)\n",
            "nonlinearity = 'relu'\n",
            "num_layers = 2\n",
            "output     = needle.Tensor([[[0.44404802 0.         0.         ... 0.40933007 0.         0.        ]\n",
            "  [0.36274207 0.         0.   ...     ... 0.2760712  0.         0.        ]\n",
            "  [0.23384504 0.         0.         ... 0.         0.         0.        ]]])\n",
            "output_    = tensor([[[0.3188, 0.0000, 0.0000,  ..., 0.0000, 0.2979, 0.1378],\n",
            "         [0.1179, 0.0000, 0.0000,  ..., 0.0000, 0.191...0, 0.2790, 0.2065],\n",
            "         [0.2095, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.4511]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "seq_length = 13\n",
            "x          = array([[[ 4.77290660e-01,  6.36361837e-01,  5.57979226e-01, ...,\n",
            "         -6.58042431e-01,  8.00202489e-02,  2.0712502...34191707e-02,  4.89012867e-01, ...,\n",
            "          7.29337990e-01,  1.65894330e-01,  1.58021319e+00]]],\n",
            "      dtype=float32)\n",
            "\n",
            "\u001b[1m\u001b[31mtests/hw4/test_sequence_models.py\u001b[0m:134: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "args = (<function assert_allclose.<locals>.compare at 0x7a3956c2a7a0>, array([[[0.00000000e+00, 1.83601081e-02, 0.00000000e+0...        0.        , 0.8353585 , 0.        , 0.00372666, 0.        ,\n",
            "         0.        , 0.        ]]], dtype=float32))\n",
            "kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "\n",
            "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(func)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92minner\u001b[39;49;00m(*args, **kwds):\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mwith\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._recreate_cm():\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mreturn\u001b[39;49;00m func(*args, **kwds)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AssertionError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Not equal to tolerance rtol=1e-05, atol=1e-05\u001b[0m\n",
            "\u001b[1m\u001b[31mE           \u001b[0m\n",
            "\u001b[1m\u001b[31mE           Mismatched elements: 221 / 360 (61.4%)\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max absolute difference: 0.9738041\u001b[0m\n",
            "\u001b[1m\u001b[31mE           Max relative difference: 7.6754236\u001b[0m\n",
            "\u001b[1m\u001b[31mE            x: array([[[0.000000e+00, 1.836011e-02, 0.000000e+00, 0.000000e+00,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.000000e+00, 2.301897e-01, 1.446227e-01, 0.000000e+00,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.000000e+00, 6.659625e-01, 5.292792e-01, 0.000000e+00],...\u001b[0m\n",
            "\u001b[1m\u001b[31mE            y: array([[[0.      , 0.      , 0.254758, 0.      , 0.002099, 0.70214 ,\u001b[0m\n",
            "\u001b[1m\u001b[31mE                    0.09098 , 0.      , 0.      , 0.172987, 0.      , 0.      ],\u001b[0m\n",
            "\u001b[1m\u001b[31mE                   [0.866482, 0.147851, 0.192661, 0.027246, 0.      , 0.384569,...\u001b[0m\n",
            "\n",
            "args       = (<function assert_allclose.<locals>.compare at 0x7a3956c2a7a0>, array([[[0.00000000e+00, 1.83601081e-02, 0.00000000e+0...        0.        , 0.8353585 , 0.        , 0.00372666, 0.        ,\n",
            "         0.        , 0.        ]]], dtype=float32))\n",
            "func       = <function assert_array_compare at 0x7a39776e6320>\n",
            "kwds       = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-05, atol=1e-05', 'verbose': True}\n",
            "self       = <contextlib._GeneratorContextManager object at 0x7a39776d9510>\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/lib/python3.10/contextlib.py\u001b[0m:79: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-tanh-True-True-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-tanh-True-True-1-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-tanh-True-True-1-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-tanh-True-True-1-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-tanh-True-True-12-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-tanh-True-True-12-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-tanh-True-True-12-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-tanh-True-True-12-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-tanh-False-True-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-tanh-False-True-1-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-tanh-False-True-1-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-tanh-False-True-1-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-tanh-False-True-12-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-tanh-False-True-12-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-tanh-False-True-12-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-tanh-False-True-12-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-relu-True-True-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-relu-True-True-1-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-relu-True-True-1-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-relu-True-True-12-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-relu-True-True-12-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-relu-True-True-12-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-relu-True-True-12-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-relu-False-True-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-relu-False-True-1-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-relu-False-True-1-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-relu-False-True-1-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-relu-False-True-12-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-relu-False-True-12-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-relu-False-True-12-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cpu-relu-False-True-12-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-tanh-True-True-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-tanh-True-True-1-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-tanh-True-True-1-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-tanh-True-True-1-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-tanh-True-True-12-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-tanh-True-True-12-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-tanh-True-True-12-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-tanh-True-True-12-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-tanh-False-True-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-tanh-False-True-1-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-tanh-False-True-1-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-tanh-False-True-1-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-tanh-False-True-12-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-tanh-False-True-12-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-tanh-False-True-12-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-tanh-False-True-12-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-relu-True-True-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-relu-True-True-1-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-relu-True-True-1-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-relu-True-True-1-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-relu-True-True-12-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-relu-True-True-12-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-relu-True-True-12-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-relu-True-True-12-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-relu-False-True-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-relu-False-True-1-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-relu-False-True-1-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-relu-False-True-12-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-relu-False-True-12-1-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-relu-False-True-12-11-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn_cell[cuda-relu-False-True-12-11-15]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-1-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-1-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-1-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-1-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-1-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-1-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-1-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-1-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-1-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-1-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-1-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-1-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-1-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-1-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-1-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-1-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-12-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-12-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-12-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-12-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-12-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-12-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-12-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-12-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-12-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-12-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-12-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-12-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-12-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-12-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-12-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-True-True-12-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-1-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-1-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-1-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-1-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-1-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-1-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-1-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-1-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-1-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-1-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-1-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-1-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-1-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-1-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-1-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-1-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-12-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-12-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-12-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-12-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-12-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-12-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-12-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-12-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-12-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-12-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-12-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-12-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-12-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-12-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-12-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-tanh-False-True-12-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-1-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-1-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-1-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-1-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-1-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-1-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-1-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-1-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-1-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-1-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-1-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-1-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-1-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-1-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-1-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-12-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-12-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-12-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-12-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-12-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-12-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-12-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-12-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-12-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-12-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-12-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-12-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-12-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-12-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-12-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-True-True-12-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-1-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-1-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-1-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-1-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-1-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-1-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-1-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-1-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-1-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-1-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-1-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-1-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-1-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-1-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-12-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-12-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-12-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-12-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-12-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-12-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-12-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-12-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-12-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-12-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-12-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-12-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-12-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-12-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-12-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cpu-relu-False-True-12-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-1-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-1-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-1-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-1-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-1-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-1-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-1-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-1-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-1-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-1-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-1-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-1-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-1-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-1-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-1-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-1-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-12-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-12-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-12-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-12-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-12-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-12-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-12-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-12-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-12-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-12-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-12-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-12-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-12-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-12-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-12-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-True-True-12-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-1-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-1-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-1-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-1-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-1-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-1-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-1-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-1-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-1-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-1-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-1-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-1-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-1-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-1-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-1-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-1-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-12-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-12-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-12-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-12-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-12-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-12-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-12-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-12-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-12-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-12-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-12-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-12-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-12-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-12-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-12-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-tanh-False-True-12-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-1-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-1-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-1-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-1-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-1-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-1-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-1-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-1-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-1-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-1-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-1-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-1-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-1-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-1-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-1-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-12-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-12-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-12-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-12-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-12-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-12-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-12-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-12-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-12-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-12-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-12-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-12-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-12-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-12-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-12-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-True-True-12-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-1-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-1-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-1-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-1-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-1-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-1-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-1-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-1-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-1-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-1-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-1-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-1-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-1-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-12-1-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-12-1-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-12-1-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-12-1-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-12-1-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-12-1-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-12-1-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-12-1-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-12-11-1-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-12-11-1-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-12-11-1-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-12-11-1-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-12-11-15-1-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-12-11-15-1-13]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-12-11-15-2-1]\u001b[0m - AssertionError: \n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1mtest_rnn[cuda-relu-False-True-12-11-15-2-13]\u001b[0m - AssertionError: \n",
            "\u001b[31m======================== \u001b[31m\u001b[1m311 failed\u001b[0m, \u001b[32m329 passed\u001b[0m, \u001b[33m1163 deselected\u001b[0m\u001b[31m in 34.38s\u001b[0m\u001b[31m =========================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pytest -l -v -k \"test_rnn\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk9B_uHKY1mr",
        "outputId": "6dd69162-4223-4b78-c776-ef7f36fd602c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submit\n",
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0\n",
            "rootdir: /content/drive/MyDrive/10714/hw4\n",
            "plugins: typeguard-4.4.1, anyio-3.7.1\n",
            "\u001b[1mcollecting ... \u001b[0mUsing needle backend\n",
            "collected 10 items / 9 deselected / 1 selected                                                     \u001b[0m\n",
            "\n",
            "tests/hw4/test_sequence_models.py \n",
            "Submitting rnn...\n",
            "Grader test 1 passed\n",
            "Grader test 2 failed: Failed: incorrect output\n",
            "Grader test 3 failed: Failed: incorrect output\n",
            "Grader test 4 passed\n",
            "Grader test 5 failed: Failed: incorrect output\n",
            "Grader test 6 failed: Failed: incorrect output\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "Grader test 7 failed: Failed: incorrect output\n",
            "Grader test 8 failed: Failed: incorrect output\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "Grader test 9 failed: Failed: incorrect output\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "Grader test 10 failed: Failed: incorrect output\n",
            "Grader test 11 failed: Failed: incorrect output\n",
            "<class 'needle.backend_ndarray.ndarray.NDArray'>\n",
            "Grader test 12 failed: Failed: incorrect output\n",
            "\u001b[31mF\u001b[0m\n",
            "\n",
            "============================================= FAILURES =============================================\n",
            "\u001b[31m\u001b[1m____________________________________________ submit_rnn ____________________________________________\u001b[0m\n",
            "\u001b[33m========================================= warnings summary =========================================\u001b[0m\n",
            "tests/hw4/test_sequence_models.py::submit_rnn\n",
            "  /usr/local/lib/python3.10/dist-packages/_pytest/python.py:1627: PluggyTeardownRaisedWarning: A plugin raised an exception during an old-style hookwrapper teardown.\n",
            "  Plugin: mugrade, Hook: pytest_pyfunc_call\n",
            "  Failed: \n",
            "  For more information see https://pluggy.readthedocs.io/en/stable/api_reference.html#pluggy.PluggyTeardownRaisedWarning\n",
            "    self.ihook.pytest_pyfunc_call(pyfuncitem=self)\n",
            "\n",
            "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
            "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m tests/hw4/test_sequence_models.py::\u001b[1msubmit_rnn\u001b[0m - Failed\n",
            "\u001b[31m=========================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m9 deselected\u001b[0m, \u001b[33m1 warning\u001b[0m\u001b[31m in 14.22s\u001b[0m\u001b[31m ============================\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m mugrade submit \"qLQ8FORcSVgmmINbWMnS\" -k \"rnn\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_goF0tOgY1mr"
      },
      "source": [
        "## Part 5: Long short-term memory network [10 points]\n",
        "In `python/needle/nn/nn_sequence.py`, implement `Sigmoid`.\n",
        "\n",
        "$$\\sigma(x) = \\frac{1}{1 + \\text{exp}(-x)}$$\n",
        "\n",
        "In `python/needle/nn/nn_sequence.py`, implement `LSTMCell`.\n",
        "\n",
        "\\begin{align*}\n",
        "i &= \\sigma(xW_{ii} + b_{ii} + hW_{hi} + b_{hi}) \\\\\n",
        "f &= \\sigma(xW_{if} + b_{if} + hW_{hf} + b_{hf}) \\\\\n",
        "g &= \\text{tanh}(xW_{ig} + b_{ig} + hW_{hg} + b_{hg}) \\\\\n",
        "o &= \\sigma(xW_{io} + b_{io} + hW_{ho} + b_{ho}) \\\\\n",
        "c^\\prime &= f * c + i * g \\\\\n",
        "h^\\prime &= o * \\text{tanh}(c^\\prime)\n",
        "\\end{align*}\n",
        "\n",
        "where $\\sigma$ is the sigmoid function, and $i$, $f$, $g$, $o$ are the input, forget, cell, and output gates, respectively.\n",
        "\n",
        "All weights and biases should be uniformly initialized on the interval $\\displaystyle\\pm\\frac{1}{\\sqrt{\\verb|hidden_size|}}$.\n",
        "\n",
        "Now implement `LSTM` in `python/needle/nn/nn_sequence.py`, which applies a multi-layer LSTM RNN to an input sequence. For each element in the input sequence, each layer computes the following function:\n",
        "\n",
        "\\begin{align*}\n",
        "i_t &= \\sigma(x_tW_{ii} + b_{ii} + h_{(t-1)}W_{hi} + b_{hi}) \\\\\n",
        "f_t &= \\sigma(x_tW_{if} + b_{if} + h_{(t-1)}W_{hf} + b_{hf}) \\\\\n",
        "g_t &= \\text{tanh}(x_tW_{ig} + b_{ig} + h_{(t-1)}W_{hg} + b_{hg}) \\\\\n",
        "o_t &= \\sigma(x_tW_{io} + b_{io} + h_{(t-1)}W_{ho} + b_{ho}) \\\\\n",
        "c_t &= f * c_{(t-1)} + i * g \\\\\n",
        "h_t &= o * \\text{tanh}(c_t)\n",
        "\\end{align*}\n",
        "\n",
        "where $h_t$ is the hidden state at time $t$, $c_t$ is the cell state at time $t$, $x_t$ is the input at time $t$, $h_{(t-1)}$ is the hidden state of the layer at time $t-1$ or the initial hidden state at time $0$, and $i_t$, $f_t$, $g_t$, $o_t$ are the input, forget, cell, and output gates at time $t$ respectively.\n",
        "\n",
        "In a multi-layer LSTM, the input $x_t^{(l)}$ of the $l$-th layer ($l \\ge 2$) is the hidden state $h_t^{(l-1)}$ of the previous layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnfxJaOfY1mr"
      },
      "outputs": [],
      "source": [
        "!python3 -m pytest -l -v -k \"test_lstm\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWftRXw4Y1ms"
      },
      "outputs": [],
      "source": [
        "!python3 -m mugrade submit \"YOUR KEY HERE\" -k \"lstm\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ec0XJdFY1ms"
      },
      "source": [
        "## Part 6: Penn Treebank dataset [10 points]\n",
        "\n",
        "In word-level language modeling tasks, the model predicts the probability of the next word in the sequence, based on the words already observed in the sequence. You will write support for the Penn Treebank dataset, which consists of stories from the Wall Street Journal, to train and evaluate a language model on word-level prediction.\n",
        "\n",
        "In `python/needle/data/datasets/ptb_dataset.py`, start by implementing the `Dictionary` class, which creates a dictionary from a list of words, mapping each word to a unique integer.\n",
        "\n",
        "Next, we will use this `Dictionary` class to create a corpus from the train and test txt files in the Penn Treebank dataset that you downloaded at the beginning of the notebook. Implement the `tokenize` function in the `Corpus` class to do this.\n",
        "\n",
        "In order to prepare the data for training and evaluation, you will next implement the `batchify` function. Starting from sequential data, batchify arranges the dataset into columns. For instance, with the alphabet as the sequence and batch size 4, we'd get\n",
        "\n",
        "```\n",
        "┌ a g m s ┐\n",
        "│ b h n t │\n",
        "│ c i o u │\n",
        "│ d j p v │\n",
        "│ e k q w │\n",
        "└ f l r x ┘\n",
        "```\n",
        "\n",
        "These columns are treated as independent by the model, which means that the dependence of e. g. 'g' on 'f' cannot be learned, but allows more efficient batch processing.\n",
        "\n",
        "Next, implement the `get_batch` function. `get_batch` subdivides the source data into chunks of length `bptt`. If source is equal to the example output of the batchify function, with a bptt-limit of 2, we'd get the following two `Tensor`s for i = 0:\n",
        "```\n",
        "┌ a g m s ┐ ┌ b h n t ┐\n",
        "└ b h n t ┘ └ c i o u ┘\n",
        "```\n",
        "Note that despite the name of the function, the subdivison of data is not done along the batch dimension (i.e. dimension 1), since that was handled by the batchify function. The chunks are along dimension 0, corresponding to the seq_len dimension in the LSTM or RNN. Also, as per the function docs, the second returned `Tensor` (the targets) should be reshaped to be 1-dimensional."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBG3MyTYY1ms"
      },
      "outputs": [],
      "source": [
        "!python3 -m pytest -l -v -k \"ptb\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVPD9v-NY1ms"
      },
      "outputs": [],
      "source": [
        "!python3 -m mugrade submit \"YOUR KEY HERE\" -k \"ptb\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZQb0E03Y1ms"
      },
      "source": [
        "## Part 7: Training a word-level language model [10 points]\n",
        "\n",
        "Finally, you will use the `RNN` and `LSTM` components you have written to construct a language model that we will train on the Penn Treebank dataset.\n",
        "\n",
        "First, in `python/needle/nn/nn_sequence.py` implement `Embedding`. Consider we have a dictionary with 1000 words. Then for a word which indexes into this dictionary, we can represent this word as a one-hot vector of size 1000, and then use a linear layer to project this to a vector of some embedding size.\n",
        "\n",
        "In `apps/models.py`, you can now implement `LanguageModel`. Your language model should consist of\n",
        "\n",
        "- An embedding layer (which maps word IDs to embeddings)\n",
        "- A sequence model (either RNN or LSTM)\n",
        "- A linear layer (which outputs probabilities of the next word)\n",
        "\n",
        "In `apps/simple_ml.py` implement `epoch_general_ptb`, `train_ptb`, and `evaluate_ptb`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "es0gjOryY1ms"
      },
      "outputs": [],
      "source": [
        "!python3 -m pytest -l -v -k \"language_model_implementation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1PQl3T6Y1ms"
      },
      "outputs": [],
      "source": [
        "!python3 -m pytest -l -v -k \"language_model_training\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ObXcgoyY1ms"
      },
      "outputs": [],
      "source": [
        "!python3 -m mugrade submit \"YOUR KEY HERE\" -k \"language_model\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TopAl3X2Y1ms"
      },
      "source": [
        "Now, you can train your language model on the Penn Treebank dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dT2e18S4Y1ms"
      },
      "outputs": [],
      "source": [
        "import needle as ndl\n",
        "sys.path.append('./apps')\n",
        "from models import LanguageModel\n",
        "from simple_ml import train_ptb, evaluate_ptb\n",
        "\n",
        "device = ndl.cpu()\n",
        "corpus = ndl.data.Corpus(\"data/ptb\")\n",
        "train_data = ndl.data.batchify(corpus.train, batch_size=16, device=ndl.cpu(), dtype=\"float32\")\n",
        "model = LanguageModel(30, len(corpus.dictionary), hidden_size=10, num_layers=2, seq_model='rnn', device=ndl.cpu())\n",
        "train_ptb(model, train_data, seq_len=1, n_epochs=1, device=device)\n",
        "evaluate_ptb(model, train_data, seq_len=40, device=device)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}